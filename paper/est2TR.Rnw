\documentclass[AMA,Times1COL]{WileyNJDv5}
\usepackage{amsmath, amssymb} % math
\usepackage{array} % math
\usepackage{multirow} % multicolumn and multirow
\usepackage{booktabs} % nicer tables
\usepackage{nameref} % reference appendices with names
\usepackage[dvipsnames,table]{xcolor}
\usepackage{orcidlink} % for ORCID symbol with link
\definecolor{lightgray}{gray}{0.9} % color for tables
\usepackage{pdflscape} % rotated landscape
\usepackage{afterpage} % floating landscape
\DeclareMathOperator*{\plim}{plim} % limit in probability

\articletype{Research Article}%
\received{}
\revised{}
\accepted{}
\journal{}
\volume{}
\copyyear{}
\startpage{}
\raggedbottom

%% hyperref options
\hypersetup{
  bookmarksopen=true,
  breaklinks=true,
  pdfsubject={},
  pdfkeywords={},
  colorlinks=true,
  linkcolor=black,
  anchorcolor=black,
  citecolor=blue,
  urlcolor=blue,
}

<< "main-setup", include = FALSE >>=
## knitr options
library(knitr)
opts_chunk$set(fig.height = 4,
               echo = FALSE,
               warning = FALSE,
               message = FALSE,
               cache = FALSE,
               eval = TRUE)

## printed digits
options(scipen = 100000)

## should sessionInfo be printed at the end?
Reproducibility <- TRUE
@
<< "package" >>=
## packages
library(confMeta)
library(ggplot2)
library(twotrials)
library(kableExtra)
library(dplyr)
@
<< "data" >>=
## data from RESPIRE 1 (Table 3 in <https://doi.org/10.1183/13993003.02052-2017>)
cirr14r1 <- c(0.4, 0.91) # attention 97.5% CI!
cilogrr14r1 <- log(cirr14r1) # attention 97.5% CI!
logrr14r1 <- log(0.61)
selogrr14r1 <- (cilogrr14r1[2] - cilogrr14r1[1])/(2*qnorm(p = (1 + 0.975)/2))
cilogrr14r1 <- logrr14r1 + c(-1, 1)*selogrr14r1*qnorm(p = 0.975) # 95% CI
cirr14r1 <- exp(cilogrr14r1) # 95% CI
cirr28r1 <- c(0.64, 1.48) # attention 97.5% CI!
cilogrr28r1 <- log(cirr28r1) # attention 97.5% CI!
logrr28r1 <- log(0.98)
selogrr28r1 <- (cilogrr28r1[2] - cilogrr28r1[1])/(2*qnorm(p = (1 + 0.975)/2))
cilogrr28r1 <- logrr28r1 + c(-1, 1)*selogrr28r1*qnorm(p = 0.975) # 95% CI
cirr28r1 <- exp(cilogrr28r1) # 95% CI

## data from RESPIRE 2 (Table 3 in <https://doi.org/10.1183/13993003.02053-2017>)
cirr14r2 <- c(0.59, 1.17) # attention 95.1% CI!
cilogrr14r2 <- log(cirr14r2) # attention 95.1% CI!
logrr14r2 <- log(0.8313)
selogrr14r2 <- (cilogrr14r2[2] - cilogrr14r2[1])/(2*qnorm(p = (1 + 0.951)/2))
cilogrr14r2 <- logrr14r2 + c(-1, 1)*selogrr14r2*qnorm(p = 0.975) # 95% CI
cirr14r2 <- exp(cilogrr14r2) # 95% CI
cirr28r2 <- c(0.30, 1.02) # attention 99.9% CI!
cilogrr28r2 <- log(cirr28r2) # attention 99.9% CI!
logrr28r2 <- log(0.5493)
selogrr28r2 <- (cilogrr28r2[2] - cilogrr28r2[1])/(2*qnorm(p = (1 + 0.999)/2))
cilogrr28r2 <- logrr28r2 + c(-1, 1)*selogrr28r2*qnorm(p = 0.975) # 95% CI
cirr28r2 <- exp(cilogrr28r2) # 95% CI

## ## results for 14 days treatment group
## twotrials(null = 0, t1 = logrr14r1, t2 = logrr14r2, se1 = selogrr14r1,
##           se2 = selogrr14r2, alternative = "less", level = 0.95)
## ## results for 28 days treatment group
## twotrials(null = 0, t1 = logrr28r1, t2 = logrr28r2, se1 = selogrr28r1,
##           se2 = selogrr28r2, alternative = "less", level = 0.95)

## data from ORBIT 3 and ORBIT 4
## (p. 219 in <https://doi.org/10.1016/S2213-2600(18)30427-2>)
cihr3 <- c(0.71, 1.38) # 95% CI
ciloghr3 <- log(cihr3) # 95% CI
loghr3 <- log(0.99)
seloghr3 <- (ciloghr3[2] - ciloghr3[1])/(2*qnorm(p = 0.975))
cihr4 <- c(0.53, 0.97) # 95% CI
ciloghr4 <- log(cihr4) # 95% CI
loghr4 <- log(0.72)
seloghr4 <- (ciloghr4[2] - ciloghr4[1])/(2*qnorm(p = 0.975))
cilogrr3 <- c(0.65, 1.12) # 95% CI
cilogrr3 <- log(cilogrr3) # 95% CI
logrr3 <- log(0.85)
selogrr3 <- (cilogrr3[2] - cilogrr3[1])/(2*qnorm(p = 0.975))
cilogrr4 <- c(0.48, 0.82) # 95% CI
cilogrr4 <- log(cilogrr4) # 95% CI
logrr4 <- log(0.63)
selogrr4 <- (cilogrr4[2] - cilogrr4[1])/(2*qnorm(p = 0.975))

## ## results for primary endpoint (HR)
## twotrials(null = 0, t1 = loghr3, t2 = loghr4, se1 = seloghr3,
##           se2 = seloghr4, alternative = "less", level = 0.95)
## ## results for secondary endpoint (RR)
## twotrials(null = 0, t1 = logrr3, t2 = logrr4, se1 = selogrr3,
##           se2 = selogrr4, alternative = "less", level = 0.95)
@

\begin{document}

%% %% title, authors, affiliations, mail
%% \title{\vspace{-3em} \textbf{\textsf{
%%       Combined \textit{P}-value Functions for Compatible Effect Estimation and
%%       Hypothesis Testing in Drug Regulation
%% }}}
%% \author{
%%   Samuel Pawel \orcidlink{0000-0003-2779-320X}
%%   \and
%%   Małgorzata Roos \orcidlink{0000-0001-9878-6969}
%%   \and
%%   Leonhard Held \orcidlink{0000-0002-8686-5325}
%% }
%% \date{
%%   Epidemiology, Biostatistics and Prevention Institute (EBPI) \\
%%   Center for Reproducible Science (CRS) \\
%%   University of Zurich \\
%%   \texttt{\{samuel.pawel,malgorzata.roos,leonhard.held\}@uzh.ch} \\ ~ \\
%%   March 13, 2025
%% }

\title{Combined \textit{P}-value Functions for Compatible Effect Estimation and Hypothesis Testing in Drug Regulation}

\author{Samuel Pawel}

\author{Małgorzata Roos}

\author{Leonhard Held}

\authormark{Pawel \textsc{et al.}}
\titlemark{Combined \textit{P}-value Functions for Compatible Effect Estimation and Hypothesis Testing in Drug Regulation}

\address{\orgdiv{Epidemiology, Biostatistics and Prevention Institute (EBPI), Center for Reproducible Science (CRS)}, \orgname{University of Zurich}, \orgaddress{\state{Zurich}, \country{Switzerland}}}


\corres{Samuel Pawel, Epidemiology, Biostatistics and Prevention Institute, Hirschengraben 84, 8001, Zurich, Switzerland. \email{samuel.pawel@uzh.ch}}

\abstract[Abstract]{The two-trials rule in drug regulation requires statistically
  significant results from two pivotal trials to demonstrate efficacy. However,
  it is unclear how the effect estimates from both trials should be combined to
  quantify the drug effect. Fixed-effect meta-analysis is commonly used but may
  yield confidence intervals that exclude the value of no effect even when the
  two-trials rule is not fulfilled. We systematically address this by recasting
  the two-trials rule and meta-analysis in a unified framework of combined
  \textit{p}-value functions, where they are variants of Wilkinson's and
  Stouffer's combination methods, respectively. This allows us to obtain
  compatible combined \textit{p}-values, effect estimates, and confidence
  intervals, which we derive in closed-form. Additionally, we provide new
  results for Edgington's, Fisher's, Pearson's, and Tippett's \textit{p}-value
  combination methods. When both trials have the same true effect, all methods
  can consistently estimate it, although some show bias. When true effects
  differ, the two-trials rule and Pearson's method are conservative (converging
  to the less extreme effect), Fisher's and Tippett's methods are
  anti-conservative (converging to the more extreme effect), and Edgington's
  method and meta-analysis are balanced (converging to a weighted average).
  Notably, Edgington's confidence intervals asymptotically always include
  individual trial effects, while meta-analytic confidence intervals shrink to a
  point at the weighted average effect. We conclude that all of these methods
  may be appropriate depending on the estimand of interest. We implement
  combined \textit{p}-value function inference for two trials in the R package
  \texttt{twotrials}, allowing researchers to easily perform compatible
  hypothesis testing and effect estimation.}

\keywords{Confidence interval, estimand, median estimate, meta-analysis,
  two-trials rule}


\maketitle

\section{Introduction}

The ``two-trials rule'' in drug regulation requires ``\emph{at least two
adequate and well-controlled studies, each convincing on its own}'' for the
demonstration of drug efficacy and subsequent market approval
\citep[p.3]{FDA1998}. This criterion reflects the need for ``substantiation''
and ``replication'' of scientific results \citep[p.8]{FDA2019}, and is typically
implemented by requiring the \textit{p}-values from the two trials to be statistically
significant at the conventional (one-sided) $\alpha = 0.025$ level. However,
this procedure alone does not provide a combined effect estimate nor a
confidence interval (CI), and it has been suggested to pool the estimates with
fixed-effect meta-analysis for this purpose \citep{Fisher1999b, Lu2001,
  Maca2002}. Yet, the meta-analytic CI and point estimate are not always
compatible with the two-trials rule. The meta-analytic CI may exclude the null
value while the two-trials rule is not fulfilled, leading to discrepancies that
are difficult to interpret and communicate.

<< "RESPIRE-trials" >>=
## RESPIRE trials
t1 <- logrr14r1
t2 <- logrr14r2
se1 <- selogrr14r1
se2 <- selogrr14r2
z1 <- t1/se1
z2 <- t2/se2
p1 <- pnorm(q = z1)
p2 <- pnorm(q = z2)
ci1 <- t1 + c(-1, 1)*se1*qnorm(p = 0.975)
ci2 <- t2 + c(-1, 1)*se2*qnorm(p = 0.975)
semeta <- 1/sqrt(1/se1^2 + 1/se2^2)
tmeta <- (t1/se1^2 + t2/se2^2)*semeta^2
cimeta <- tmeta + c(-1, 1)*qnorm(p = 0.975)*semeta
zmeta <- (tmeta - 0)/semeta
pmeta <- pnorm(q = zmeta)

## (1 - 2*alpha^2) CI
cimeta2 <- tmeta + c(-1, 1)*qnorm(p = 1 - 2*0.025^2)*semeta
cimeta3 <- tmeta + c(-1, 1)*qnorm(p = 1 - 2*0.05^2)*semeta
@



The results from the two RESPIRE trials \citep{Aksamit2018, DeSoyza2018,
  Chotirmall2018} in Table~\ref{tab:respire} illustrate this phenomenon. While
the \textit{p}-value for the null hypothesis of no effect from RESPIRE 1 is $p =
\Sexpr{round(p1, 3)} < 0.025$, the \textit{p}-value from RESPIRE 2 is $p =
\Sexpr{round(p2, 3)} > 0.025$. Hence, the two-trials rule is not fulfilled at
$\alpha = 0.025$. At the same time, the 95\% CI for the log rate ratio based on
combining the trials' log rate ratio effect estimates with fixed-effect
meta-analysis ranges from $\Sexpr{round(cimeta[1], 2)}$ to
$\Sexpr{round(cimeta[2], 2)}$ and thus excludes the value of 0.

\begin{table}[!htb]
  \centering
  \caption{Results from the RESPIRE trials regarding the effect of ciprofloxacin
    after 14 days for the treatment of non-cystic fibrosis bronchiectasis
    \citep{Aksamit2018, DeSoyza2018, Chotirmall2018}.}
  \label{tab:respire}
  \begin{tabular}{l c c c}
    \toprule
    & \multicolumn{1}{c}{\textbf{Log rate ratio}} & \textbf{Confidence interval (95\%)} & \multicolumn{1}{c}{\textbf{\textit{P}-value (one-sided)}} \\
    \midrule
    RESPIRE 1 & $\Sexpr{round(t1, 2)}$ & $\Sexpr{round(ci1[1], 2)}$ to $\Sexpr{round(ci1[2], 2)}$ & $\Sexpr{round(p1, 3)}$ \\

    RESPIRE 2 & $\Sexpr{round(t2, 2)}$ & $\Sexpr{round(ci2[1], 2)}$ to $\phantom{-}\Sexpr{round(ci2[2], 2)}$ & $\Sexpr{round(p2, 3)}$ \\
    \midrule
    Meta-analysis & $\Sexpr{round(tmeta, 2)}$ & $\Sexpr{round(cimeta[1], 2)}$ to $\Sexpr{round(cimeta[2], 2)}$ & $\Sexpr{round(pmeta, 3)}$ \\
    \bottomrule
  \end{tabular}
\end{table}

A first attempt at resolving the apparent paradox could be to realize that the
confidence level of the CI does not align with the level of the implicit test
underlying the two-trials rule. Since the two-trials rule decision is based on
two independent tests at level $\alpha = 0.025$, the overall test is at level
$\alpha^2 = \Sexpr{0.025^2}$, thus one could instead take a $(1 - 2 \, \alpha^2)
\times 100\% = \Sexpr{100*(1 - 2*0.025^2)}\%$ meta-analytic CI
\citep{Fisher1999, Senn2021}. For the RESPIRE trials, this would lead to a
meta-analytic $\Sexpr{100*(1 - 2*0.025^2)}\%$ CI from $\Sexpr{round(cimeta2[1],
  2)}$ to $\Sexpr{round(cimeta2[2], 2)}$ which includes the value of 0 and hence
aligns with the two-trials rule decision. However, the level $\alpha = 0.025$ is
arbitrary and it would be desirable to have a CI that is compatible with the
two-trials rule for any level, which is still not the case. For example, for
$\alpha = 0.05$, the two-trials rule is still not fulfilled, while the $(1 - 2
\, \alpha^2) \times 100\% = \Sexpr{100*(1 - 2*0.05^2)}\%$ meta-analytic CI from
$\Sexpr{round(cimeta3[1], 2)}$ to $\Sexpr{round(cimeta3[2], 2)}$ excludes zero.

Despite the widespread use of the two-trials rule in regulatory decision-making
\citep{Zhang2020}, it remains unclear how point and interval estimation should
be reconciled with it. This paper aims to resolve this issue with a new
approach. The key idea is to look at both the two-trials rule and meta-analysis
from the perspective of \textit{p}-value functions \citep{Bender_etal2005,
  XieSingh2013, Fraser2019, InfangerSchmidt-Trucksass2019, Marschner2024} and
\textit{p}-value combination methods \citep{HedgesOlkin1985, Singh_etal2005,
  cousins2007annotated, Xie_etal2011, Heard2018}. The two-trials rule can be
understood as a combined \textit{p}-value function based on the squared maximum
of two \textit{p}-values \citep{Held2024} which is a special case of Wilkinson's
combination method \citep{Wilkinson1951}, while meta-analysis corresponds to the
combined \textit{p}-value function based on Stouffer's \textit{p}-value
combination method \citep{Stouffer1949} with suitable weights. Both can be used
to obtain combined \textit{p}-values for the null hypothesis of no effect, CIs,
and point estimates. These quantities are compatible in the sense that the
(two-sided) \textit{p}-value for a null value is less than $\alpha$ if and only
if the null value is excluded by the $(1 - \alpha) \times 100\%$ CI, and that
the point estimate is included in the CI at any confidence level $(1 - \alpha)
\in (0,1)$. However, as we will show, the two methods implicitly target
different estimands, which explains their different behaviors, and highlights
the need to choose the method depending on the scientific question and
corresponding estimand of interest. Moreover, the combined \textit{p}-value
function pespective suggests considering alternative \textit{p}-value
combination methods, for example, Edgington's method based on the sum of
\textit{p}-values \citep{Edgington1972} or Fisher's method based on the product
of \textit{p}-values \citep{Fisher1934}. All these \textit{p}-value combination
methods have been studied before in terms of hypothesis testing properties, such
as admissibility or monotonicity \citep{Birnbaum1954, HedgesOlkin1985}. In this
paper, we take an alternative estimation perspective motivated by practical
issues in drug regulation.

This paper is organized as follows: We begin by summarizing the general theory
of combined \textit{p}-value functions (Section~\ref{sec:combinedp}), followed by
investigating combined \textit{p}-value functions based on the two-trials rule
(Section~\ref{sec:2tr}), meta-analysis (Section~\ref{sec:fema}), Tippett's
method (Section~\ref{sec:tippett}), Fisher's and Pearson's methods
(Section~\ref{sec:fisher}), and Edgington's method (Section~\ref{sec:edgington})
in more detail. For each, we derive corresponding point and interval estimates
and investigate their properties. Results from two pairs of clinical trials are
analyzed to illustrate the characteristics of the methods
(Section~\ref{sec:application}). Extensions to more than two trials are
discussed in Section~\ref{sec:extensions}. The paper ends with concluding
discussions, limitations, and an outlook for future research
(Section~\ref{sec:discussion}). Appendix~\ref{app:rpackage} illustrates our R
package \texttt{twotrials} for conducting \textit{p}-value function inference,
while Appendix~\ref{app:technicaldetails} provides additional technical details.

\section{Combined \textit{p}-value functions}
\label{sec:combinedp}
Suppose that two trials yield the effect estimates $\hat{\theta}_{1}$ and
$\hat{\theta}_{2}$ with corresponding standard errors $\sigma_{1}$ and
$\sigma_{2}$, each estimate quantifying the effect of the treatment in the
corresponding trial. Typically, it is reasonable to assume that the effect
estimates (after suitable transformation) are approximately normally distributed
around the trial-specific true effects $\theta_{1}$ and $\theta_{2}$ with
variance equal to their squared standard error, i.e., $\hat{\theta}_{i} \mid
\theta_{i} \sim \mathrm{N}(\theta_{i}, \sigma^{2}_{i})$ for $i \in \{1, 2\}$.
One-sided \textit{p}-values can then be computed by
\begin{equation}
  \label{eq:pnorm}
  p_i(\mu) =
  \begin{cases}
    1-\Phi(Z_i)  & \text{for} ~ H_{1i} \colon \theta_i > \mu ~ \text{(alternative = "greater")} \\
    \Phi(Z_i) &  \text{for} ~ H_{1i} \colon \theta_i < \mu ~ \text{(alternative = "less")} \\
    \end{cases}
\end{equation}
with $z$-values
\begin{equation*}
  Z_i = \frac{\hat \theta_i - \mu}{\sigma_i},
\end{equation*}
cumulative distribution function of the standard normal distribution
$\Phi(\cdot)$, null value $\mu$, and alternative hypothesis $H_{1i}$ chosen
based on the orientation of the effect. For example, if a positive effect
indicates treatment benefit, the alternative "greater" would be chosen. We will
not consider \textit{p}-values with two-sided alternatives here, as the hypotheses
tested in clinical trials usually have a well-defined direction. Moreover,
combined \textit{p}-value functions based on two-sided \textit{p}-values can behave
irregularly, e.g., they can be non-monotone so that the resulting confidence
sets consist of empty or disjoint intervals, which is unintuitive and hard to
communicate \citep{Held_etal2024b}.

A combined \textit{p}-value function $p(\mu)$ is then defined by the function $g$
\begin{equation*}
  p(\mu) = g\left(p_{1}(\mu), p_{2}(\mu)\right),
\end{equation*}
which combines the individual \textit{p}-value functions $p_{1}(\mu)$ and $p_{2}(\mu)$
into a \textit{p}-value function $p(\mu)$, which is a valid \textit{p}-value function in the
sense of having a uniform distribution for a particular $\mu$ if both
$p_{1}(\mu)$ and $p_{2}(\mu)$ are also uniformly distributed for that $\mu$
\citep{XieSingh2013, Held_etal2024b}. A two-sided $(1 - \alpha) \times 100\%$
CI can then be obtained by determining the null values $\mu$
for which the \textit{p}-value function is equal to $\alpha/2$ and $1 - \alpha/2$. The
so-called median estimate is given by the null value $\mu$ for which the
\textit{p}-value function equals 1/2 \citep{Fraser2017}. To obtain these quantities, it
is useful to define a ``combined estimation function''
\begin{equation*}
  \hat{\mu}(a) = \left\{\mu : p(\mu) = a \right\}
\end{equation*}
which is the inverse of the combined \textit{p}-value function. It returns the median
estimate when setting $a = 1/2$, while the limits of a $(1 - \alpha) \times
100\%$ CI are obtained from $a = \alpha/2$ and $a = 1 -
\alpha/2$, respectively. As we will show, combined estimation functions (and
hence the median estimate and any CI) are available in
closed-form for several combined \textit{p}-value functions, including the two-trials
rule and meta-analysis.

\begin{figure}[!htb]
<< "one-and-two-sided-pfs", fig.height = 2.5 >>=
pfunnorm. <- function(mu, t, se, alternative = "greater") {
    z <- (t - mu)/se
    if (alternative == "greater") {
        p <- 1 - pnorm(q = z)
    } else if (alternative == "less") {
        p <- pnorm(q = z)
    } else { # two-sided
        p <- 2*(1 - pnorm(q = abs(z)))
    }
    return(p)
}
pfunnorm <- Vectorize(FUN = pfunnorm.)

## illustration of p-value function, CI, median estimate, centrality function
museq <- seq(-3, 3, length.out = 500)
t <- 0
se <- 0.8
col <- adjustcolor(col = "#009E73", alpha.f = 0.95)
par(mfrow = c(1, 2), las = 1, "mar" = c(2.3, 4.1, 0.5, 1.5),
    "oma" = c(0, 0, 0, 0), xpd = TRUE)
pbks <- seq(0.2, 0.8, 0.2)
pfun1 <- pfunnorm(mu = museq, t = t, se = se)
alpha <- 0.05
ci <- t + c(-1, 1)*se*qnorm(p = 1 - alpha/2)
plot(museq, pfun1, type = "l", lwd = 1.5, xlab = "", ylim = c(0, 1),
     ylab = bquote(italic(p) * "-value (one-sided)"), xaxt = "n", yaxt = "n")
mtext(side = 1, text = bquote(mu), line = 1.5)
axis(side = 2, at = pbks)
segments(x0 = c(ci[1], t, ci[2]), y0 = c(alpha/2, 0.5, 1 - alpha/2), y1 = -0.02,
         lty = 2, col = col)
segments(x0 = c(ci[1], t, ci[2]), y0 = c(alpha/2, 0.5, 1 - alpha/2), x1 = -3.1,
         lty = 2, col = col)
## mtext(side = 2, text = c(alpha/2, 0.5, 1 - alpha/2), line = 0.25,
##       at = c(alpha/2, 0.5, 1 - alpha/2), col = col, cex = 0.9)
axis(side = 2, at = c(alpha/2, 0.5, 1 - alpha/2), col.ticks = col, col.axis = col,
     cex.axis = 0.8)
## axis(side = 1, at = c(ci[1], t, ci[2]), labels = rep("", 3), col.ticks = col,
##      col.axis = col, cex.axis = 0.8)
arrows(x0 = ci[1], x1 = ci[2], y0 = -0.1, code = 3, length = 0.075, col = col, angle = 90)
points(x = t, y = -0.1, col = col, pch = 20)

plot(museq, 2*pmin(pfun1, 1 - pfun1), type = "l", lwd = 1.5, xlab = "",
     ylim = c(0, 1),
     ylab = bquote(italic(p) * "-value (two-sided)"),
     xaxt = "n", yaxt = "n")
mtext(side = 1, text = bquote(mu), line = 1.5)
axis(side = 2, at = pbks)
segments(x0 = c(ci[1], t, ci[2]), y0 = c(alpha, 1, alpha), y1 = -0.02,
         lty = 2, col = col)
segments(x0 = c(ci[2], t), y0 = c(alpha, 1), x1 = -3.1, lty = 2, col = col)
## mtext(side = 2, text = c(alpha/2, 0.5, 1 - alpha/2), line = 0.25,
##       at = c(alpha/2, 0.5, 1 - alpha/2), col = col, cex = 0.9)
axis(side = 2, at = c(alpha, 1), col.ticks = col, col.axis = col,
     cex.axis = 0.8)
## axis(side = 1, at = c(ci[1], t, ci[2]), labels = rep("", 3), col.ticks = col,
##      col.axis = col, cex.axis = 0.8)
arrows(x0 = ci[1], x1 = ci[2], y0 = -0.1, code = 3, length = 0.075, col = col, angle = 90)
points(x = t, y = -0.1, col = col, pch = 20)
@
\caption{Illustration of a one-sided \textit{p}-value function with alternative =
  "greater" (left plot), corresponding two-sided \textit{p}-value function (right
  plot), and corresponding 95\% CI and median estimate.}
\label{lab:pfunillustration}
\end{figure}

In practice, it is informative to plot the \textit{p}-value function for a range of
null values $\mu$, see the left plot in Figure~\ref{lab:pfunillustration}. For
this purpose, it may also be converted to a two-sided \textit{p}-value function using
the transformation $2\min\{p(\mu), 1 - p(\mu)\}$, known as ``centrality
function'' \citep{XieSingh2013}. Such a two-sided \textit{p}-value function then peaks
at the median estimate, and it can be thresholded at $\alpha$ to conveniently
read off the $(1 - \alpha) \times 100\%$ CI \citep{Held_etal2024b}, see the
right plot in Figure~\ref{lab:pfunillustration}.


When both trials have the same underlying true effect ($\theta_{1} = \theta_{2}
= \theta$), sometimes called ``one population assumption'' or ``homogeneity''
\citep{Shun2005, Zhan2022}, a CI based on a combined \textit{p}-value function has
correct coverage and the median estimate is median unbiased for the true common
effect $\theta$, i.e., the probability of the median estimate being greater than
$\theta$ is equal to the probability of it being smaller than $\theta$
\citep[see e.g.,][]{XieSingh2013}. However, it is unclear how other operating
characteristics (e.g., mean bias or CI width) behave for different combined
\textit{p}-value functions $g$, and how they behave when the true effects are not the
same ($\theta_{1} \neq \theta_{2}$), known as ``two populations assumption'' or
``heterogeneity'' \citep{Shun2005, Zhan2022}. In the following, we will
investigate this in detail for the two-trials rule, meta-analysis, and four
other types of combined \textit{p}-value functions. As these investigations are
somewhat technical, readers may choose to look only at the summary in
Table~\ref{tab:summaries} and then jump directly to the applications in
Section~\ref{sec:application}.

\afterpage{
\begin{landscape}
\begingroup
\renewcommand{\arraystretch}{1.3} % Default value: 1
\begin{table}[!htb]
  \centering
  \caption{Summary of combined \textit{p}-value functions and corresponding estimation
    functions. All are based on the alternative ``greater''. The median estimate
    is obtained from setting $a = 1/2$, while the limits of a $(1 - \alpha)
    \times 100\%$ confidence interval (CI) are obtained from $a = \alpha/2$ and
    $a = 1 - \alpha/2$, respectively.}
  \label{tab:summaries}
  \rowcolors{1}{}{gray!15}
  \resizebox{1\linewidth}{!}{%
  \begin{tabular}{p{0.11\linewidth}   p{0.22\linewidth}  p{0.22\linewidth}  >{\footnotesize}p{0.26\linewidth}}
    \toprule
    \multicolumn{1}{c}{\textbf{Method}} &
    \multicolumn{1}{c}{\textbf{Combined \textit{p}-value function}} &
    \multicolumn{1}{c}{\textbf{Combined estimation function}} &
    \multicolumn{1}{c}{\textbf{Properties}} \\
    \midrule

    \textbf{Two-trials rule} \newline Maximum \textit{p}-value, special case of Wilkinson's method, Section~\ref{sec:2tr} &
    \vfill
    \centering
    \( p_{\text{2TR}}(\mu) = \max\{p_{1}(\mu), p_{2}(\mu)\}^{2} \)
    \newline ~ \newline
    R function \texttt{twotrials::p2TR}
    &
    \vfill
    \centering
    \( \hat{\mu}_{\text{2TR}}(a) =
    \min\{\hat{\theta}_1 + \sigma_1 \, z_{\sqrt{a}}, \hat{\theta}_2 + \sigma_2 \, z_{\sqrt{a}}\} \)
    \newline ~ \newline
    R function \texttt{twotrials::mu2TR}
    &
    -- Targets least extreme true effect (conservative) \newline
    -- Mean-biased when trials have the same true effects \newline
    -- CI shrinks to point with decreasing standard errors \newline
    -- Median estimate not equal to observed effect estimates when the same estimates in both trials \newline
    -- Median estimate standard error can be larger than trial standard errors
    \\

    \textbf{Fixed-effect \newline meta-analysis} \newline Weighted Stouffer's method, inverse-normal method, Section~\ref{sec:fema} &
    \vfill
    \centering
    \(p_{\text{MA}}(\mu) = 1 - \Phi(Z_{\text{MA}}) \)
    \newline ~ \newline
    with~\(Z_{\text{MA}} = \frac{\Phi^{-1}\{1-p_1(\mu)\}/\sigma_{1} + \Phi^{-1}\{1-p_2(\mu)\}/\sigma_{2}}{\sqrt{1/\sigma_{1}^{2} + 1/\sigma_{2}^{2}}}\)
    \newline ~ \newline
    R function \texttt{twotrials::pMA}
    &
    \vfill
    \centering
    \(\hat{\mu}_{\text{MA}}(a) = \hat{\theta}_{\text{MA}} + \sigma_{\text{MA}} \, z_{a}\)
    \newline \newline with ~
    \parbox{3cm}{\(\begin{aligned}
      \sigma_{\text{MA}}^{2} &= 1/(1/\sigma_{1}^{2} + 1/\sigma_{2}^{2}) \\
      \hat{\theta}_{\text{MA}} &= (\hat{\theta}_{1}/\sigma_{1}^{2} + \hat{\theta}_{2}/\sigma_{2}^{2}) \, \sigma_{\text{MA}}^{2}
      \end{aligned}\)}
    \newline ~ \newline
    R function \texttt{twotrials::muMA}
    &
    -- Targets weighted average effect (inverse squared standard error weights) \newline
    -- Mean-unbiased when the same true effects \newline
    -- CI shrinks to point with decreasing standard errors \newline
    -- Median estimate equals observed effect estimates when the same estimates in both trials \newline
    -- Median estimate standard error cannot be larger than trial standard errors
    \\

    \textbf{Tippett's method} \newline Minimum \textit{p}-value, special case of Wilkinson's method, Section~\ref{sec:tippett} &
    \vfill
    \centering
    \( p_{\text{T}}(\mu) = 1 - (1 - \min\{p_{1}(\mu), p_{2}(\mu)\})^{2} \)
    \newline ~ \newline
    R function \texttt{twotrials::pTippett}
    &
    \vfill
    \centering
    \( \hat{\mu}_{\text{T}}(a) =
    \max\{\hat{\theta}_1 - \sigma_1 \, z_{\sqrt{1 - a}}, \hat{\theta}_2 - \sigma_2 \, z_{\sqrt{1 - a}}\} \)
    \newline ~ \newline
    R function \texttt{twotrials::muTippett}
    &
    -- Targets most extreme true effect (anti-conservative) \newline
    -- Mean-biased when the same true effects \newline
    -- CI shrinks to point with decreasing standard errors \newline
    -- Median estimate not equal to observed effect estimates when the same estimates in both trials \newline
    -- Median estimate standard error can be larger than trial standard errors
    \\

    \textbf{Fisher's method} \newline Product of \textit{p}-values, Section~\ref{sec:fisher} &
    \vfill
    \centering
    \( p_{\text{F}}(\mu) = 1 - \Pr(\chi^{2}_{4} \leq F) \)
    \newline ~ \newline
    with
    \(F = -2 [\log\{p_{1}(\mu)\} + \log \{p_{2}(\mu)\}]\)
    \newline ~ \newline
    R function \texttt{twotrials::pFisher}
    &
    \vfill
    \centering
    $\hat{\mu}_{\text{F}}(a)$ not analytically available
    \newline ~ \newline
    R function \texttt{twotrials::muFisher}
    &
    -- Targets most extreme true effect (anti-conservative) \newline
    -- CI shrinks to point with decreasing standard errors \newline
    -- Median estimate not equal to observed effect estimates when the same estimates in both trials \newline
    -- Median estimate standard error can be larger than trial standard errors
    \\

    \textbf{Pearson's method} \newline Product of $1 - p$-values, Section~\ref{sec:fisher} &
    \vfill
    \centering
    \( p_{\text{P}}(\mu) = \Pr(\chi^{2}_{4} \leq K) \)
    \newline ~ \newline
    with~\(K = -2 [\log\{1 - p_{1}(\mu)\} + \log \{1 - p_{2}(\mu)\}]\)
    \newline ~ \newline
    R function \texttt{twotrials::pPearson}
    &
    \vfill
    \centering
    $\hat{\mu}_{\text{P}}(a)$ not analytically available
    \newline ~ \newline
    R function \texttt{twotrials::muPearson}
    &
    -- Targets least extreme true effect (conservative) \newline
    -- CI shrinks to point with decreasing standard errors \newline
    -- Median estimate not equal to observed effect estimates when the same estimates in both trials \newline
    -- Median estimate standard error can be larger than trial standard errors
    \\

    \textbf{Edgington's method} \newline Sum of \textit{p}-values, \newline Section~\ref{sec:edgington} &
    \vfill
    \parbox{3cm}{\(\begin{aligned}
      p_{\text{E}}(\mu) =
      \begin{cases}
        E^{2}/2 & \text{if} ~ 0 \leq E \leq 1 \\
        1 - (2 - E)^{2}/2 & \text{if} ~ 1 < E \leq 2 \\
      \end{cases}
    \end{aligned}\)}
    \newline ~ \newline
    with
    \(E = p_1(\mu) + p_2(\mu)\)
    \newline ~ \newline
    R function \texttt{twotrials::pEdgington}
    &
    \vfill
    \centering
    Median estimate analytically available
    \(\hat{\mu}_{\text{E}}(a = 1/2) = \dfrac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2}\)
    \newline ~ \newline
    $\hat{\mu}_{\text{E}}(a)$ not analytically available for \(a \neq 1/2\)
    \newline
     R function \texttt{twotrials::muEdgington}
    &
    -- Targets weighted average effect (inverse standard error weights) \newline
    -- Mean-unbiased when the same true effects \newline
    -- CI asymptotically always includes both true effects (only shrinks to point when both are equal) \newline
    -- Median estimate equals observed effect estimates when the same estimates in both trials \newline
    -- Median estimate standard error can be larger than trial standard errors
    \\
    \bottomrule
  \end{tabular}
  }
\end{table}
\endgroup
\end{landscape}
}

\subsection{The two-trials rule (maximum method)}
\label{sec:2tr}
The two-trials rule is fulfilled if $\max\{p_{1}, p_{2}\} \leq \alpha$, or
equivalently if
\begin{align}
  \label{eq:2trials}
  p_{\text{2TR}}(\mu) = \max\left\{p_{1}(\mu), p_{2}(\mu)\right\}^{2} \leq \alpha^{2}.
\end{align}
The formulation using the squared maximum~\eqref{eq:2trials} may be preferable
because $p_{\text{2TR}}(\mu)$ is a valid \textit{p}-value, i.e., it has a uniform
distribution if both $p_{1}(\mu)$ and $p_{2}(\mu)$ are also uniformly
distributed for a particular $\mu$ \citep{Held2024}. The combined
\textit{p}-value function~\eqref{eq:2trials} is also a special case of
Wilkinson's \textit{p}-value combination method based on the $r$th smallest out of $k$
\textit{p}-values with $r = k = 2$ \citep{Wilkinson1951}. This relationship can be used
to generalize the two-trials rule to different settings while preserving type I
error control at level $\alpha^2$, for example, settings with three rather than
two trials \citep{Rosenkranz2023}. We will discuss such extensions to more than
two trials in Section~\ref{sec:extensions} and focus first on effect estimation
for two trials.

\subsubsection{Effect estimation}
In order to obtain a CI and a point estimate based on the
two-trials rule, we can equate the combined \textit{p}-value
function~\eqref{eq:2trials} to some value $a \in (0, 1)$ and solve for the null
value~$\mu$. This leads to the combined estimation function
\begin{equation}
  \label{eq:2trialsest}
  \hat{\mu}_{\text{2TR}}(a) =
  \begin{cases}
    \min\{\hat{\theta}_1 + \sigma_1 \, z_{\sqrt{a}}, \hat{\theta}_2 + \sigma_2 \, z_{\sqrt{a}}\} & \text{for alternative = "greater"} \\
    \max\{\hat{\theta}_1 - \sigma_1 \, z_{\sqrt{a}},  \hat{\theta}_2 - \sigma_2 \, z_{\sqrt{a}}\} & \text{for alternative = "less"}
  \end{cases}
\end{equation}
with $z_{q}$ the $q \times 100\%$ quantile of the standard normal distribution.
For $a = 1/2$ the median estimate is obtained, while the limits of an $(1
- \alpha) \times 100\%$ CI can be obtained from $a = \alpha/2$
and $a = 1 - \alpha/2$.

Now assume that the standard errors of both trials are the same ($\sigma_{1} =
\sigma_{2} = \sigma$) and the alternative is "greater". The median estimate is
then
\begin{equation}
  \label{eq:2trpe}
  \hat{\mu}_{\text{2TR}}(1/2) = \min\{\hat{\theta}_{1}, \hat{\theta}_{2}\} + \sigma \, \underbrace{z_{\sqrt{1/2}}}_{\Sexpr{round(qnorm(sqrt(0.5)), 2)}}
\end{equation}
and the 95\% CI is given by
\begin{equation}
  \label{eq:2trci}
  \bigg[
    \min\{\hat{\theta}_{1}, \hat{\theta}_{2}\} + \sigma \, \underbrace{z_{\sqrt{0.025}}}_{\Sexpr{round(qnorm(sqrt(0.025)), 2)}},\,
    \min\{\hat{\theta}_{1}, \hat{\theta}_{2}\} + \sigma \, \underbrace{z_{\sqrt{0.975}}}_{\Sexpr{round(qnorm(sqrt(0.975)), 2)}}
  \bigg].
\end{equation}
Both seem counterintuitive. For instance, if the trial effect estimates are the
same ($\hat{\theta}_{1} = \hat{\theta}_{2} = \hat{\theta}$), the median
estimate~\eqref{eq:2trpe} is shifted away from the observed estimate by $\sigma
\times z_{\sqrt{1/2}} \approx \sigma \times \Sexpr{round(qnorm(sqrt(0.5)), 2)}$,
and also the CI~\eqref{eq:2trci} is not centered around it. This is illustrated
in Figure~\ref{fig:extremeExamples} (panels A and C), where the hypothetical
trial effect estimates are identical, but the median estimates based on the
two-trials rule (black) are larger. Moreover, the CI~\eqref{eq:2trci} is skewed
in the sense that the distance between the upper limit and the median estimate
is larger than the distance between the lower limit and the median estimate
although the estimates are the same.


While this CI has correct coverage and the median estimate is
median unbiased we may look at other operating characteristics. The expectation
of the median estimate~\eqref{eq:2trpe} can be derived to be
\begin{equation}
  \label{eq:exp2tr}
  \mathrm{E}\left[\hat{\mu}_{\text{2TR}}(1/2)\right] =
  \theta_{1}\, \Phi\left(\frac{\theta_{2} - \theta_{1}}{\sqrt{2}\,\sigma}\right) +
  \theta_{2}\, \Phi\left(\frac{\theta_{1} - \theta_{2}}{\sqrt{2}\,\sigma}\right) +
  \sigma\, \left\{
  z_{\sqrt{1/2}} -
  \sqrt{2}\,\phi\, \left(\frac{\theta_{2} - \theta_{1}}{\sqrt{2}\,\sigma}\right)
  \right\}
\end{equation}
where $\phi(\cdot)$ denotes the density function of the standard normal
distribution, see Appendix~\ref{app:expectation} for details. If the true
effects from the two trials coincide ($\theta_{1} = \theta_{2} = \theta$) the
first two terms of the expectation~\eqref{eq:exp2tr} reduce to the common effect
$\theta$, whereas the last term reduces to $\sigma \times (z_{\sqrt{1/2}} -
1/\sqrt{\pi}) \approx \sigma \times \Sexpr{round(qnorm(sqrt(0.5)) - 1/sqrt(pi),
  3)}$. Hence, the median estimate with~\eqref{eq:2trpe} is negatively biased,
yet the bias vanishes as the standard error decreases. In a similar way, one can
show that the median estimate for the alternative "less" is positively biased,
so the median estimate from the two-trials rule exhibits a conservative bias in
both cases.

Another interesting operating characteristic is the standard error of the median
estimate, elaborated in more detail in Appendix~\ref{app:ses}. Notably, the
standard error of the two-trials rule depends not only on the standard errors of
the trials, but also on the true trial effects.

An intuitively desirable property is that the standard error of a combined
estimate should not be larger than either of the trials' standard errors.
Assuming again that the true trial effects and standard errors coincide, the
two-trials rule satisfies, as the standard error takes the simple form
\begin{equation*}
  \label{eq:se2tr}
  \sigma_{\text{2TR}} =
  %% \sqrt{\mathrm{Var}\left[\hat{\mu}_{\text{2TR}}(1/2)\right]} =
  \sigma \sqrt{1 - 1/\pi}
  \approx \sigma \times 0.83,
\end{equation*}
so is approximately $17\%$ smaller than the standard errors of each individual
trial. However, this is no longer the case when the trial standard errors
differ, see Appendix~\ref{app:ses}.


\begin{figure}[!htb]
<< "hypothetical-examples", fig.height = 5 >>=
c <- 2 # relative sample size of study 2 to study 1
nsmall <- 5 # small per-group sample size
nlarge <- 500 # big per-group sample size
settingsgrid <- data.frame(t1 = c(2.5, 3.5, 2.5, 3.5),
                           t2 = c(2.5, 1.5, 2.5, 1.5),
                           se1 = sqrt(2/c(nsmall, nsmall, nlarge, nlarge)),
                           se2 = sqrt(2/c(nsmall, nsmall, nlarge, nlarge)/c),
                           label = c("A) Identical and imprecise estimates",
                                     "B) Different and imprecise estimates",
                                     "C) Identical and precise estimates",
                                     "D) Different and precise estimates"))
museq <- seq(0, 5, length.out = 10000)
xlim <- c(0, 5)
input_p <- "greater"
alternative <- "greater"
alpha <- 0.05
null <- 0
resList <- lapply(X = seq(1, nrow(settingsgrid)), FUN = function(i) {
    res <- twotrials(null = null,
                     t1 = settingsgrid$t1[i], t2 = settingsgrid$t2[i],
                     se1 = settingsgrid$se1[i], se2 = settingsgrid$se2[i],
                     alternative = "greater", level = 1 - alpha)
    plotres <- plot(res, xlim = xlim, two.sided = TRUE, plot = FALSE)
    colnames(plotres)[1] <- "type"
    isummaries <- res$isummaries
    summaries <- res$summaries
    colnames(isummaries)[1] <- "type"
    colnames(summaries)[1] <- "type"
    list("p" = data.frame(plotres, settingsgrid[i,]),
         "summaries" = data.frame(rbind(isummaries, summaries[,1:5]), settingsgrid[i,]))
})
pDF <- do.call("rbind", lapply(X = resList, function(x) x$p))
summariesDF <- do.call("rbind", lapply(X = resList, function(x) x$summaries))
typelevels <- c("Trial 1", "Trial 2", "Two-trials rule", "Meta-analysis",
                "Tippett",  "Fisher", "Pearson", "Edgington")
summariesDF$type <- factor(summariesDF$type, levels = rev(typelevels))
pDF$type <- factor(pDF$type, levels = rev(typelevels))

lty <- c(rep("22", 2), rep("solid", 6))
names(lty) <- unique(summariesDF$type)
cols <- c("Trial 1" = "#CC79A7F2", "Trial 2" = "#888888F2",
          "Meta-analysis" = "#56B4E9F2", "Two-trials rule" = "#000000F2",
          "Tippett" = "#E69F00F2", "Edgington" = "#009E73F2",
          "Fisher" = "#F0E442F2", "Pearson" = "#0072B2F2")
ggplot(data = pDF, aes(x = mu, y = p, color = type, linetype = type)) +
    facet_wrap(~ label) +
    geom_hline(yintercept = alpha, lty = "longdash", alpha = 0.1) +
    geom_line() +
    geom_pointrange(data = summariesDF,
                    aes(xmin = lower, xmax = upper, x = est, y = 1.15),
                    position = position_dodge2(width = 0.2),
                    fatten = 0.5) +
    ## geom_vline(data = summariesDF, aes(xintercept = upper, color = type),
    ##            alpha = 0.2) +
    ## geom_vline(data = summariesDF, aes(xintercept = lower, color = type),
    ##            alpha = 0.2) +
    scale_linetype_manual(values = lty,
                          guide = guide_legend(reverse = TRUE)) +
    scale_color_manual(values = cols,
                       guide = guide_legend(reverse = TRUE)) +
    scale_y_continuous(breaks = c(seq(0.25, 1, 0.25), 0.05),
                        sec.axis = sec_axis(~ 1 - .,
                                           breaks = c(seq(0, 0.75, 0.25), 0.95),
                                           labels = scales::percent,
                                           name = "Confidence")) +
    labs(x = "Effect size", y = bquote(italic(p) * "-value"),
         color = NULL, linetype = NULL) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background = element_rect(fill = "#00000005"))
@
\caption{Four hypothetical pairs of effect estimates and standard errors from
  two trials. The standard errors are assumed to be of the form $\sigma =
  \sqrt{2/n}$. The sample size $n$ in trial 1 is set to \Sexpr{nsmall}
  (imprecise) or \Sexpr{nlarge} (precise), and in trial 2 to twice the sample
  size of trial 1. The two-sided \textit{p}-value functions of the individual trials
  (dashed lines), and the combined \textit{p}-value functions (solid lines) based on
  the two-trials rule, fixed-effect meta-analysis, Tippett's, Fisher's,
  Pearson's, and Edgington's methods, and are shown along with the corresponding
  95\%~CIs and median estimates (top). All \textit{p}-values are based on the
  alternative "\Sexpr{input_p}" and then converted to two-sided \textit{p}-values via
  the centrality function $2\min\{p, 1 - p\}$.}
\label{fig:extremeExamples}
\end{figure}


\subsubsection{Asymptotics}
Suppose now that the sample size of the trials increases and in turn the
standard errors of the effect estimates decrease toward zero. The combined
estimation function~\eqref{eq:2trialsest} then converges to
\begin{align*}
  \plim_{\sigma_1, \sigma_2 \downarrow 0} \hat{\mu}_{\text{2TR}}(a) =
    \begin{cases}
    \min\{\theta_1, \theta_2\} & \text{for alternative = "greater"} \\
    \max\{\theta_1, \theta_2\} & \text{for alternative = "less"},
  \end{cases}
\end{align*}
see Appendix~\ref{app:asymptotics} for details. Hence, the median estimate ($a =
1/2$) and any CI limit ($a \neq 1/2$) approach
$\min\{\hat{\theta}_1, \hat{\theta}_2\}$ or $\max\{\hat{\theta}_1,
\hat{\theta}_2\}$, depending on the alternative hypothesis. This means that the
CI shrinks to the more conservative of the two effects, while
in case they coincide ($\theta_1 = \theta_2 = \theta$) it shrinks to the common
effect $\theta$. Both scenarios are illustrated in
Figure~\ref{fig:extremeExamples}: In case of very small standard errors and
different effect estimates (panel D), the CI based on the
two-trials rule (black) is tightly concentrated around the smaller effect
estimate, while for identical effect estimates (panel C), it is tightly
concentrated around the common effect estimate.

\subsection{Fixed-effect meta-analysis (Stouffer's method)}
\label{sec:fema}
We will now compare the \textit{p}-value function from the two-trials rule with its
meta-analysis counterpart. The combined \textit{p}-value based on fixed-effect
meta-analysis is given by
\begin{align}
  \label{eq:pMeta}
  p_{\text{MA}}(\mu) =
    \begin{cases}
    1 - \Phi(Z_{\text{MA}}) & \text{for alternative = "greater"} \\
    \Phi(Z_{\text{MA}}) & \text{for alternative = "less"}
  \end{cases}
\end{align}
with
\begin{align}
  Z_{\text{MA}}
  = \frac{Z_{1}/\sigma_{1} + Z_{2}/\sigma_{2}}{\sqrt{1/\sigma_{1}^{2} + 1/\sigma_{2}^{2}}}
  = \frac{\hat{\theta}_{\text{MA}} - \mu}{\sigma_{\text{MA}}} \label{eq:zMeta}
\end{align}
where
\begin{align}
  \label{eq:tMA}
 \hat{\theta}_{\text{MA}} = \frac{\hat{\theta}_{1}/\sigma_{1}^{2} +
    \hat{\theta}_{2}/\sigma_{2}^{2}}{1/\sigma_1^2 + 1/\sigma_2^2}
\end{align}
and
\begin{align}
  \label{eq:seMA}
  \sigma_{\text{MA}} = \frac{1}{\sqrt{1/\sigma_{1}^{2} + 1/\sigma_{2}^{2}}}.
\end{align}
The first equation in~\eqref{eq:zMeta} represents Stouffer's \textit{p}-value
combination method (after transforming \textit{p}-values to $z$-values) using
inverse standard errors as weights \citep{cousins2007annotated}, whereas the
second equation in~\eqref{eq:zMeta} shows the corresponding representation via
the meta-analytically pooled estimate~\eqref{eq:tMA} and standard
error~\eqref{eq:seMA} \citep{Borenstein2010}. While meta-analytic pooling could
be extended to the random-effects model, this is typically not desired with only
two studies for three reasons. First, the interest is in the true effects
underlying the studies. Second, random-effects variance estimation is unreliable
with only two studies. Finally, even if there is effect heterogeneity,
fixed-effect meta-analysis is a valid procedure which estimates a well-defined
average true effect \citep{Rice_etal2018}.

\subsubsection{Effect estimation}
To obtain meta-analytic CIs and point estimates we can also
equate the \textit{p}-value function~\eqref{eq:pMeta} to $a$ and solve for $\mu$. This
leads to the combined estimation function
\begin{align*}
  \hat{\mu}_{\text{MA}}(a) =
  \begin{cases}
   \hat{\theta}_{\text{MA}} + \sigma_{\text{MA}} \, z_{a}  & \text{for alternative = "greater"} \\
   \hat{\theta}_{\text{MA}} - \sigma_{\text{MA}} \, z_{a}  & \text{for alternative = "less"}.
  \end{cases}
\end{align*}
When $a = 1/2$ we obtain $\hat{\theta}_{\text{MA}}$ as the median estimate,
while $a = \alpha/2$ and $a = 1 - \alpha/2$ give the limits of the $(1 -\alpha)
\times 100\%$ CI corresponding to the usual fixed-effect
meta-analytic Wald CI.

The standard error of the meta-analytic median estimate is given by
$\sigma_{\text{MA}}$ from~\eqref{eq:seMA}, and it has two desirable properties:
First, it it is never larger than either of trials' standard errors
($\sigma_{\text{MA}} \leq \min\{\sigma_1, \sigma_2\}$). Second, under effect
homogeneity, the standard error is the smallest among all unbiased estimators of
the common effect \citep{HedgesOlkin1985}. Both properties do not hold for the
two-trials rule and the other \textit{p}-value combination methods discussed
below.

\subsubsection{Asymptotics}
Since the meta-analytic combined estimation function is a linear combination of
normally distributed effect estimates, its distribution is also normal and given
by
\begin{align*}
  \hat{\mu}_{\text{MA}}(a) \sim
  \mathrm{N}\left(\frac{\theta_{1}}{1 + c} + \frac{\theta_{2}}{1 + 1/c} -
  \frac{z_a}{\sqrt{1/\sigma^2_1 + 1/\sigma^2_2}}, \,
  \frac{1}{1/\sigma^2_1 + 1/\sigma^2_2} \right)
\end{align*}
for the alternative ``greater'' and with variance ratio $c =
\sigma^{2}_{1}/\sigma^{2}_{2}$. For the alternative ``less'', the minus in the
mean has to be replaced with a plus. The median estimate ($a = 1/2$) hence
targets the weighted average of the true effects
\begin{align*}
  \frac{\theta_{1}}{1 + c} + \frac{\theta_{2}}{1 + 1/c}
\end{align*}
while the meta-analytic CIs becomes increasingly concentrated
around the weighted average with decreasing standard errors, provided the
relative variance $c$ stays constant.

Meta-analysis thus shows a less conservative asymptotic behavior than the
two-trials rule in the sense that a more extreme effect can compensate for a
less extreme one, whereas the two-trials rule would converge to the less extreme
of the two effects. Figure~\ref{fig:extremeExamples} illustrates this asymptotic
behavior: In case both estimates are identical and the standard errors very
small (panel C), the meta-analytic CI is concentrated around the trials
estimate, while in case of different estimates the CI concentrates somewhere in
between (panel D). Since in this example the relative variance is $c = 2$, the
weighted average is slightly closer to the estimate from trial 2.

\section{Other \textit{p}-value combination methods}
While the two-trials rule and meta-analysis are the most commonly used \textit{p}-value
combination methods in practice, several other combination methods exist
\citep{HedgesOlkin1985}. In this section, we examine Tippett's, Fisher's,
Pearson's, and Edgington's methods, which can also be used to obtain combined
effect estimates, CIs, and \textit{p}-values. Although these methods are not standard
in drug regulation, they may have useful properties in certain settings, as we
will demonstrate in the following.

\subsection{Tippett's (minimum) method}
\label{sec:tippett}
 The combined \textit{p}-value from Tippett's method \citep{Tippett1931} is based on
 the minimum of the two \textit{p}-values and given by
\begin{equation*}
  p_{\text{T}}(\mu) = 1 - (1 - \min\{p_{1}(\mu), p_{2}(\mu)\})^{2}.
\end{equation*}
It is closely related to the two-trials rule in the sense that the combined
\textit{p}-value based on the alternative ``greater'' from Tippett's method is the same
as one minus the combined \textit{p}-value based on the alternative ``less'' from the
two-trials rule, and vice versa \citep{Held_etal2024b}. Similarly, Tippett's
method is a special case of Wilkinson's method based on the $r = 1$ smallest out
of $k = 2$ \textit{p}-values.

\subsubsection{Effect estimation}
Following a similar approach as with the two-trials rule, CIs
and point estimates based on Tippett's method can be obtained in closed-form
with the combined estimation function
\begin{equation}
  \label{eq:tippest}
  \hat{\mu}_{\text{T}}(a) =
  \begin{cases}
    \max\{\hat{\theta}_1 - \sigma_1 \, z_{\sqrt{1 - a}}, \hat{\theta}_2 - \sigma_2 \, z_{\sqrt{1 - a}}\} & \text{for alternative = "greater"} \\
    \min\{\hat{\theta}_1 + \sigma_1 \, z_{\sqrt{1 - a}},  \hat{\theta}_2 + \sigma_2 \, z_{\sqrt{1 - a}}\} & \text{for alternative = "less"}.
  \end{cases}
\end{equation}
The similarity to the two-trials rule is again visible as~\eqref{eq:tippest}
looks similar to the estimation function from the two-trials
rule~\eqref{eq:2trialsest} with the minimum and maximum flipped and using
different normal quantiles. The same median estimates are obtained (i.e.,
$\hat{\mu}_{\text{2TR}}(1/2) = \hat{\mu}_{\text{T}}(1/2)$) if opposite
alternatives are specified.

We can see that when the observed effect estimates are the same ($\hat{\theta}_1
= \hat{\theta}_2 = \hat{\theta}$), the median estimate ($a = 1/2$) based on
Tippett's method is not equal to $\hat{\theta}$ but shifted from it, as the
two-trials rule (see panels A and C in Figure~\ref{fig:extremeExamples} for an
illustration). Similarly, CIs obtained from Tippett's method are typically
skewed in the sense that the distances between the point estimate and the upper
and lower limits are not the same.

\subsubsection{Asymptotics}
It can be shown that as the standard errors $\sigma_1$ and $\sigma_2$ decrease,
the combined estimation function~\eqref{eq:tippest} converges to
\begin{align*}
  \plim_{\sigma_1, \sigma_2 \downarrow 0} \hat{\mu}_{\text{T}}(a) =
    \begin{cases}
    \max\{\theta_1, \theta_2\} & \text{for alternative = "greater"} \\
    \min\{\theta_1, \theta_2\} & \text{for alternative = "less"},
  \end{cases}
\end{align*}
that is, the more extreme of the two effects, see Appendix~\ref{app:asymptotics}
for details. In contrast to the two-trials rule, Tippett's method is hence
anti-conservative. This is illustrated in panel D of
Figure~\ref{fig:extremeExamples} where Tippett's CI is tightly concentrated
around the larger effect estimate.

\subsection{Fisher's and Pearson's (product) methods}
\label{sec:fisher}
Pearson's and Fisher's combination method are two closely related \textit{p}-value
combination methods, that are based on the product of \textit{p}-values, or
equivalently, the sum of the log \textit{p}-values. Fisher's method has been proposed
for combining \textit{p}-values from clinical trials \citep{Fisher1999, Rosenkranz2002,
  Shun2005}, however, using the associated \textit{p}-value function for effect
estimation in a regulatory trials setting has remained unexplored.

The combined \textit{p}-value function based on Fisher's method \citep{Fisher1934} is
given by
\begin{equation}
  \label{eq:fisher}
  p_{\text{F}}(\mu) =
  1 - \Pr\left(\chi^{2}_{4} \leq -2 [\log\{p_{1}(\mu)\} + \log \{p_{2}(\mu)\}]\right)
\end{equation}
while the combined \textit{p}-value function based on Pearson's method
\citep{Pearson1933} is given by
\begin{equation}
  \label{eq:pearson}
  p_{\text{P}}(\mu) =
  \Pr\left(\chi^{2}_{4} \leq -2 [\log\{1 - p_{1}(\mu)\} + \log \{1 - p_{2}(\mu)\}]\right).
\end{equation}
Pearson \citep{Pearson1934} proposed also another method based on the maximum of
the test statistics underlying the \textit{p}-values~\eqref{eq:fisher}
and~\eqref{eq:pearson}, but we will not consider this method here as its test
statistic does not have an exact null distribution \citep{Owen2009}. As with the
two-trials rule and Tippett's method, the combined \textit{p}-value functions of
Fisher's and Pearson's methods are related in the sense that the
\textit{p}-value function based on Fisher's method and the alternative
hypothesis ``greater'' is the same as one minus the \textit{p}-value function
based on Pearson's method and the alternative ``less'', and vice versa
\citep{Held_etal2024b}. As we will show in the following, Fisher's method also
acts in a similar anti-conservative way as Tippett's method, while Pearson's
method acts in a similar conservative way as the two-trials rule.

\subsubsection{Effect estimation}
CIs and point estimates based on Fisher's and Pearson's methods
can in general not be obtained in closed-form but require numerical
root-finding. However,
%% see \citet[Chapter 5 Appendix]{Hartung_etal2008} for approximations for a
%%   special case of Fisher's method. Another
a special case where a closed-form solution is available is when the effect
estimates and standard errors are the same in both trials ($\hat{\theta}_1 =
\hat{\theta}_2 = \hat{\theta}$ and $\sigma_1 = \sigma_2 = \sigma$). While this
is unrealistic in practice, it serves as an important soundness check to
investigate whether the methods produce reasonable estimates in the situation of
identical trial results. In this case, we obtain the following closed-form
combined estimation function for Fisher's method
\begin{equation}
  \label{eq:fisherest}
  \hat{\mu}_{\text{F}}(a) =
  \begin{cases}
    \hat{\theta} + \sigma \, z_{\exp\{-\chi^{2}_{4}(1 - a)/4\}} &  \text{for alternative = "greater"} \\
    \hat{\theta} - \sigma \, z_{\exp\{-\chi^{2}_{4}(1 - a)/4\}} &  \text{for alternative = "less"} \\
  \end{cases}
\end{equation}
and for Pearson's method
\begin{equation}
  \label{eq:pearsonest}
  \hat{\mu}_{\text{P}}(a) =
  \begin{cases}
    \hat{\theta} + \sigma \, z_{\exp\{-\chi^{2}_{4}(a)/4\}} &  \text{for alternative = "greater"} \\
    \hat{\theta} - \sigma \, z_{\exp\{-\chi^{2}_{4}(a)/4\}} &  \text{for alternative = "less"} \\
  \end{cases}
\end{equation}
with $\chi^{2}_{4}(a)$ the $a\times 100\%$ quantile of the chi-squared
distribution with four degrees of freedom. Importantly, the median estimates ($a
= 1/2$) from both methods do not equal the observed estimate $\hat{\theta}$ but
are shifted away from it by $z_{\exp\{-\chi^{2}_{4}(1/2)/2\}} \approx
\Sexpr{round(qnorm(p = exp(-qchisq(p = 0.5, df = 4)/4)), 2)}$ standard errors
$\sigma$, similar to the two-trials rule and Tippett's method. Another
similarity is that the CI is skewed since the distance between the lower and
upper limits to the point estimate is not the same.


\subsubsection{Asymptotics}
To understand the asymptotic behavior of Fisher's and Pearson's method, we may
again examine their combined estimation functions for decreasing standard
errors. When the true effects are equal ($\theta_1 = \theta_2 = \theta$), both
Fisher's and Pearson's median estimates will converge toward it, which is clear
from the theory of \textit{p}-value functions but can also be informally seen
from~\eqref{eq:fisherest} and~\eqref{eq:pearsonest} shrinking toward the common
effect estimate for a decreasing standard error. On the other hand, when the
true effects are unequal, it can then be shown that
\begin{align*}
  \plim_{\sigma_1, \sigma_2 \downarrow 0} \hat{\mu}_{\text{F}}(a) =
    \begin{cases}
    \max\{\theta_1, \theta_2\} & \text{for alternative = "greater"} \\
    \min\{\theta_1, \theta_2\} & \text{for alternative = "less"},
  \end{cases}
\end{align*}
and
\begin{align*}
  \plim_{\sigma_1, \sigma_2 \downarrow 0} \hat{\mu}_{\text{P}}(a) =
    \begin{cases}
    \min\{\theta_1, \theta_2\} & \text{for alternative = "greater"} \\
    \max\{\theta_1, \theta_2\} & \text{for alternative = "less"},
  \end{cases}
\end{align*}
see Appendix~\ref{app:approxmu} for details. This means that the combined
estimation functions converge toward the more extreme effect for Fisher's method
(e.g., the maximum of two positively oriented effects), and the less extreme
effect for Pearson's method (e.g., the minimum of two positively oriented
effects). The behavior is similar to Tippett's method and the two-trials rule
where one method acts anti-conservative (Fisher and Tippett's methods), while
the other methods acts conservative (Pearson's method and the two-trials rule).
However, the examples in panels B and D of Figure~\ref{fig:extremeExamples}
suggest that in finite samples, Fisher's and Pearson's method remain closer to
the weighted average compared to Tippett's method and the two-trials rule.


\subsection{Edgington's (sum) method}
\label{sec:edgington}
Edgington's method based on the sum of \textit{p}-values \citep{Edgington1972} is yet
another \textit{p}-value combination method that can be used for obtaining a combined
\textit{p}-value function, and the last method that we will consider in this paper. It
is given by
\begin{equation}
  \label{eq:edgington}
  p_{\text{E}}(\mu) =
  \begin{cases}
    E^{2}/2 & \text{if} ~ 0 \leq E \leq 1 \\
    1 - (2 - E)^{2}/2 & \text{if} ~ 1 < E \leq 2 \\
    %2E - E^{2}/2 - 1 & \text{if} ~ 1 < E \leq 2 \\
  \end{cases}
\end{equation}
with $E = p_{1}(\mu) + p_{2}(\mu)$. An attractive feature is that two-sided CIs
based on Edgington's method are orientation invariant, which is not the case for
the other combined \textit{p}-value functions considered so far. That is, CIs based on
Edgington's method do not depend on the orientation of the underlying one-sided
\textit{p}-values, so the same CI is obtained regardless whether one uses \textit{p}-values
with the alternative "greater" or "less" \citep{Held_etal2024b}. Edgington's
method has previously been used in meta-analysis \citep{Held_etal2024b}, to
synthesize \textit{p}-values from original and replication studies
\citep{Held_etal2024}, and suggested as an alternative for the two-trials rule
\citep{Held2024}. However, its estimation properties in the context of two
trials remain unexplored.

\subsubsection{Effect estimation}
The median estimate based on Edgington's method has an intuitive interpretation
as the null value $\mu$ for which the sum of the \textit{p}-values is one. It can be
obtained in closed-form by
\begin{equation}
  \label{eq:edgingtonpointest}
  \hat{\mu}_{\text{E}}(1/2) =
  \frac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2}
\end{equation}
so is a weighted average of the two effect estimates, as the meta-analytic point
estimate~\eqref{eq:tMA}. However, the weights from Edgington's method are equal
to the inverse standard errors, whereas the weights from meta-analysis are equal
to the inverse squared standard errors. Thus, Edgington's method gives more
weight to smaller studies (those with larger standard errors) compared to
meta-analysis. Moreover, since the expectation of the median
estimate~\eqref{eq:edgingtonpointest} is again a weighted average of the true
effects, it follows that Edgington's median estimate is unbiased when the true
effects coincide ($\theta_1 = \theta_2 = \theta$), while in case they differ,
the median estimate targets a weighted average of the true effects, though not
the same weighted average as targeted by meta-analysis.

The standard error of Edgington's median estimate is given by
\begin{equation}
  \label{eq:se2E}
  %% \sqrt{\mathrm{Var}\left[\hat{\mu}_{\text{E}}(1/2)\right]} =
  \sigma_{\text{E}} =
  \frac{\sqrt{2}}{1/\sigma_1 + 1/\sigma_2}
\end{equation}
and is always larger than the meta-analytic standard error~\eqref{eq:seMA}, see
Appendix~\ref{app:ses}. Therefore, under effect homogeneity, Edgington's method
is less efficient than meta-analysis at estimating the common effect. Under
effect heterogeneity, however, the two methods target different estimands, so a
comparison of their standard errors is not meaningful. Finally, unlike
meta-analysis, Edgington's standard error is not always smaller or equal to
either of the two trials' standard errors. This is only the case if the standard
error ratio is $\sqrt{2} - 1 \leq \sigma_2/\sigma_1 \leq \sqrt{2} + 1$. For
example, suppose $\sigma_1 = 0.5$ and $\sigma_2 = 2$, then Edgington's standard
error is $\sqrt{2}/(2 + 0.5) = \Sexpr{round(sqrt(2)/(2 + 0.5), 3)}$, which is
greater than $\sigma_1$

In general, CIs for Edgington's method do not have closed-form solutions and
must be computed numerically. Nevertheless, as with Pearson's and Fisher's
methods, a closed-form combined estimation function is available when the effect
estimates and standard errors from both trials coincide ($\hat{\theta} =
\hat{\theta}_{1} = \hat{\theta}_{2}$ and $\sigma = \sigma_{1} = \sigma_{2}$),
which enables again analytical assessment of how the CI behaves in this
important scenario. In this case, the combined estimation function is
\begin{equation}
  \label{eq:edgingtonthesame}
  \hat{\mu}_{\text{E}}(a) =
  \begin{cases}
    \hat{\theta} + \sigma \, z_{\sqrt{a/2}} & \text{for} ~ a \leq 1/2
    \\ \hat{\theta} - \sigma \, z_{\sqrt{(1 - a)/2}} & \text{for} ~ a > 1/2 \\
  \end{cases}
\end{equation}
for the alternative "greater" and with the plus (minus) after $\hat{\theta}$
replaced with minus (plus) in~\eqref{eq:edgingtonthesame} for the alternative
"less". We can see that CIs obtained
from~\eqref{eq:edgingtonthesame} are symmetric and centered around the observed
effect estimate $\hat{\theta}$, similar to meta-analysis but unlike the
CIs from the two-trials rule, Fisher's, and Pearson's methods.
Yet, Edgington's CI is in this case narrower than the
meta-analytic CI. For example, Edgington's 95\% CI is
%% \begin{align*}
%%   \frac{-z_{\sqrt{(1 - 0.975)/2}} - z_{\sqrt{0.025/2}}}{(z_{0.975} - z_{0.025})/\sqrt{2}}
%%   = \frac{z_{1 - \sqrt{0.025/2}}}{z_{0.975}/\sqrt{2}}
%%   \approx \Sexpr{round(qnorm(1 - sqrt(0.025/2))/(qnorm(p = 0.975)/sqrt(2)), 2)}
%% \end{align*}
\Sexpr{round(100*(1 - qnorm(1 - sqrt(0.025/2))/(qnorm(p = 0.975)/sqrt(2))),1)}\%
narrower than the corresponding meta-analytic 95\% CI. Panel A of
Figure~\ref{fig:extremeExamples} illustrates this as Edgington's CI is narrower
than the meta-analytic CI, although both are centered around the same effect
estimate. However, in case the trials' effect estimates are different,
Edgington's CI can also be much wider. For instance, in panel B of
Figure~\ref{fig:extremeExamples} where the trials produced very different
results, Edgington's CI is much wider than any of the other methods. This
suggests that Edgington's method reacts to heterogeneity by widening its CI to
include both trial effect estimates.

\subsubsection{Asymptotics}
Because the median estimate based on Edgington's method is a weighted average of
two normally distributed effect estimates, it is also normally distributed
\begin{align*}
  \hat{\mu}_{\text{E}}(1/2) \sim \mathrm{N}\left(\frac{\theta_1}{1 + \sqrt{c}} + \frac{\theta_2}{1 + 1/\sqrt{c}}, \, \frac{2}{(1/\sigma_1 + 1/\sigma_2)^2}\right)
\end{align*}
with relative variance $c = \sigma_1^2/\sigma_2^2$. As the median estimate has
its mean at the weighted average
\begin{align*}
\frac{\theta_1}{1 + \sqrt{c}} + \frac{\theta_2}{1 + 1/\sqrt{c}}
\end{align*}
it is clear that it will converge toward it as the standard errors decrease.
Whether the CI shrinks to this weighted average depends on whether the true
effects are equal. In case they are, it can be informally seen that the
CI~\eqref{eq:edgingtonthesame} will shrink to the common true effect, which is
illustrated in panel C of Figure~\ref{fig:extremeExamples}. However, when the
true effects differ, the CI will not shrink to a point but remain an interval
that always includes both true effects as the limiting combined estimation
function is
\begin{equation}
  \plim_{\sigma_1, \sigma_2 \downarrow 0} \hat{\mu}_{\text{E}}(a) =
  \begin{cases}
    \min\{\theta_{1}, \theta_{2}\} & \text{for} ~ a < 1/2 \\
    \dfrac{\theta_1}{1 + \sqrt{c}} + \dfrac{\theta_2}{1 + 1/\sqrt{c}} & \text{for} ~ a = 1/2 \\
    \max\{\theta_{1}, \theta_{2}\} & \text{for} ~ a > 1/2 \\
  \end{cases}
\end{equation}
see Appendix~\ref{app:approxmu} for details. This means that CIs based on
Edgington's method will asymptotically always include both true effects, even
when the trials' sample sizes become arbitrarily large, see panel D of
Figure~\ref{fig:extremeExamples} for an illustration. This behavior is
strikingly different from meta-analysis whose CI shrinks to a point at the
weighted average, even when the true effects are not the same.


\section{Applications}
\label{sec:application}
We will now illustrate combined \textit{p}-value functions, CIs, and median estimates
on data from two different pairs of clinical trials.

\subsection{The RESPIRE trials}
We first revisit the RESPIRE trials \citep{Aksamit2018, DeSoyza2018,
  Chotirmall2018}, which were presented as motivating example in
Table~\ref{tab:respire} in the introduction. The trials investigated the effect
of ciprofloxacin in the treatment of non-cystic fibrosis bronchiectasis. Each
trial had two treatment groups (on/off treatment cycles of either 14 or 28 days
for 48 weeks) and two corresponding control groups. RESPIRE~1 showed a
substantial treatment effect in the 14-day treatment regimen (estimated log rate
ratio of $\log\widehat{\mathrm{RR}} = \Sexpr{round(logrr14r1, 2)}$ with 95\% CI
from $\Sexpr{round(cilogrr14r1[1], 2)}$ to $\Sexpr{round(cilogrr14r1[2], 2)})$,
while the benefit was less pronounced in RESPIRE~2 ($\log\widehat{\mathrm{RR}} =
\Sexpr{round(logrr14r2, 2)}$ with 95\% CI from $\Sexpr{round(cilogrr14r2[1],
  2)}$ to $\Sexpr{round(cilogrr14r2[2], 2)}$). Surprisingly, this was reversed
for the 28-day regimens, with RESPIRE~2 showing a much stronger treatment effect
($\log\widehat{\mathrm{RR}} = \Sexpr{round(logrr28r2, 2)}$ with 95\% CI from
$\Sexpr{round(cilogrr28r2[1], 2)}$ to $\Sexpr{round(cilogrr28r2[2], 2)})$ while
RESPIRE~1 showed almost no benefit ($\log\widehat{\mathrm{RR}} =
\Sexpr{round(logrr28r1, 2)}$ with 95\% CI from $\Sexpr{round(cilogrr28r1[1],
  2)}$ to $\Sexpr{round(cilogrr28r1[2], 2)})$. Figure~\ref{fig:twinstudies}
shows the \textit{p}-value functions of the two studies (dashed lines) along with
different combined \textit{p}-value functions (solid lines) and corresponding point
estimates and CIs (top). Table~\ref{tab:tabrespirecombined} shows the results in
numerical form. Of note, all results were computed with our R package
\texttt{twotrials} and Appendix~\ref{app:rpackage} shows how the results for the
14-day treatment group can be reproduced.

\begin{figure}[!htb]
<< "RESPIRE-analysis", fig.height = 5 >>=
## wrapper function to compute combined CIs, median estimates, and p-values
resFun <- function(t1, t2, se1, se2, labels, xlim, alternative, alpha, null,
                   lab1, lab2) {
    resList <- lapply(X = seq(1, length(t1)), FUN = function(i) {
        ## ordinary alpha
        res <- twotrials(null = null, t1 = t1[i], t2 = t2[i], se1 = se1[i],
                         se2 = se2[i], alternative = alternative,
                         level = 1 - alpha)
        ## for a lower alpha level to have CI decision at alpha^2
        res2 <- twotrials(null = null, t1 = t1[i], t2 = t2[i], se1 = se1[i],
                          se2 = se2[i], alternative = alternative,
                          level = 1 - 2*(alpha/2)^2)
        plotres <- plot(res, xlim = xlim, two.sided = TRUE, plot = FALSE)
        colnames(plotres)[1] <- "type"
        colnames(res$isummaries)[1] <- "type"
        colnames(res$summaries)[1] <- "type"
        res$isummaries$w2 <- res$isummaries$w1 <- NA
        summaries <- rbind(res$isummaries, res$summaries)
        summaries$lower2 <- c(NA, NA, res2$summaries$lower)
        summaries$upper2 <- c(NA, NA, res2$summaries$upper)
        summaries$labels <- labels[i]
        plotres$labels <- labels[i]
        res <- list("p" = plotres, "summaries" = summaries)
    })
    pDF <- do.call("rbind", lapply(X = resList, function(x) x$p))
    summariesDF <- do.call("rbind", lapply(X = resList, function(x) x$summaries))
    typelevels <- c("Trial 1", "Trial 2", "Two-trials rule", "Meta-analysis",
                    "Tippett",  "Fisher", "Pearson", "Edgington")
    typelabs <- c(lab1, lab2, "Two-trials rule", "Meta-analysis", "Tippett",
                  "Fisher", "Pearson", "Edgington")
    summariesDF$type <- factor(summariesDF$type, levels = rev(typelevels),
                               labels = rev(typelabs))
    pDF$type <- factor(pDF$type, levels = rev(typelevels), labels = rev(typelabs))
    list("summariesDF" = summariesDF, "pDF" = pDF)
}

## compute results for RESPIRE trials
RESPIREres <- resFun(t1 = c(logrr14r1, logrr28r1),
                     se1 = c(selogrr14r1, selogrr28r1),
                     t2 = c(logrr14r2, logrr28r2),
                     se2 = c(selogrr14r2, selogrr28r2),
                     labels = c("14-day treatment group",
                                "28-day treatment group"),
                     xlim = c(-1, 0.5),
                     alternative = "less", alpha = 0.05, null = 0,
                     lab1 = "RESPIRE 1", lab2 = "RESPIRE 2")
names(cols)[1:2] <- names(lty)[1:2] <- c("RESPIRE 1", "RESPIRE 2")

## ## save results as CSV
## RESPIREres$summariesDF |>
##         select(type, labels, lower, est, upper, p0, w1, w2) |>
##     rename("Type" = type, "Regimen" = labels, "Lower 95% CL" = lower,
##            "Point estimate" = est, "Upper 95% CL" = upper, "P-value" = p0,
##            "Weight RESPIRE 1" = w1, "Weight RESPIRE 2" = w2) |>
##     write.csv(file = "data/RESPIRE.csv", row.names = FALSE)

## plot results
ggplot(data = RESPIREres$pDF, aes(x = mu, y = p, color = type, linetype = type)) +
    facet_wrap(~ labels, ncol = 1) +
    geom_hline(yintercept = alpha, lty = "longdash", alpha = 0.1) +
    geom_line() +
    geom_pointrange(data = RESPIREres$summariesDF,
                    aes(xmin = lower2, xmax = upper2, x = est, y = 1.15),
                    position = position_dodge2(width = 0.25), fatten = 0,
                    linewidth = 0.3, alpha = 0.3) +
    geom_pointrange(data = RESPIREres$summariesDF,
                    aes(xmin = lower, xmax = upper, x = est, y = 1.15),
                    position = position_dodge2(width = 0.25),
                    fatten = 1.1) +
    ## geom_vline(data = RESPIREres$summariesDF,
    ##            aes(xintercept = upper, color = type), alpha = 0.2) +
    ## geom_vline(data = RESPIREres$summariesDF,
    ##            aes(xintercept = lower, color = type), alpha = 0.2) +
    scale_linetype_manual(values = lty, guide = guide_legend(reverse = TRUE)) +
    scale_color_manual(values = cols, guide = guide_legend(reverse = TRUE)) +
    coord_cartesian(xlim = c(-1, 0.5), ylim = c(-0.02, 1.25)) +
    scale_x_continuous(breaks = round(seq(-0.9, 0.3, 0.3), 1)) +
    scale_y_continuous(breaks = c(seq(0.25, 1, 0.25), 0.05),
                       sec.axis = sec_axis(~ 1 - .,
                                           breaks = c(seq(0, 0.75, 0.25), 0.95),
                                           labels = scales::percent,
                                           name = "Confidence")) +
    annotate(geom = "segment", arrow = arrow(length = unit(1.2, 'mm'),
                                             type = "closed"),
             alpha = 0.6,
             x = c(-1, 1)*0.02, xend = c(-1, 1)*0.2,
             y = -0.06, yend = -0.06) +
    annotate(geom = "text", alpha = 0.8, label = "Benefit",
             x = -0.1, y = -0.025, size = 2.75) +
     annotate(geom = "text", alpha = 0.8, label = "Harm",
             x = 0.1, y = -0.025, size = 2.75) +
    labs(x = "Log rate ratio", y = bquote(italic(p) * "-value"),
         color = NULL, linetype = NULL) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background = element_rect(fill = "#00000005"))
@
\caption{Results of the RESPIRE trials \citep{Aksamit2018, DeSoyza2018,
    Chotirmall2018} for the effect of ciprofloxacin over 14 days (top) or 28
  days (bottom) compared to placebo for the treatment of non-cystic fibrosis
  bronchiectasis. The two-sided \textit{p}-value functions of the individual trials
  (dashed lines), and the combined \textit{p}-value functions (solid lines) based on
  the two-trials rule, fixed-effect meta-analysis, Tippett's, Fisher's,
  Pearson's, and Edgington's methods are shown along with corresponding median
  estimates and CIs (95\% and \Sexpr{round(100*(1 - 2*0.025^2),3)}\% via
  telescope lines). All \textit{p}-values are based on the alternative
  "\Sexpr{input_p}" and then converted to two-sided \textit{p}-values via the
  centrality function $2\min\{p, 1 - p\}$.}
\label{fig:twinstudies}
\end{figure}

\begin{table}[!htb]
  \centering
  \caption{Point estimates (with implicit weights), 95\% CIs (with widths), and
    \textit{p}-values for the RESPIRE trials \citep{Aksamit2018, DeSoyza2018,
      Chotirmall2018}. Note that weigths and CI widths are computed from
    unrounded numbers and may not always exactly correspond with rounded point
    estimates and CIs.}
  \label{tab:tabrespirecombined}
<< "table-RESPIRE", results = "asis" >>=
formatNumberLaTeX. <- function(number, digits = 2) {
    if (is.na(number)) {
        return("$ $")
    }
    sprintfString <- paste0("%.", digits, "f")
    numberRound <- sprintf(sprintfString, number)
    if (number >= 0) {
        numberRound <- paste0("\\phantom{-}", numberRound)
    }
    paste0("$", numberRound, "$")
}
formatNumberLaTeX <- Vectorize(FUN = formatNumberLaTeX.)
formatCILaTeX <- function(lower, upper, digits = 2) {
    paste0(formatNumberLaTeX(number = lower, digits = digits),
           " to ",
           formatNumberLaTeX(number = upper, digits = digits))
}

dig <- 2
digPvals <- 5
RESPIREtab <- RESPIREres$summariesDF |>
    mutate(est = formatNumberLaTeX(number = est, digits = dig),
           w1 = formatNumberLaTeX(number = w1, digits = dig),
           ci = formatCILaTeX(lower = lower, upper = upper, digits = dig),
           ciwidth = formatNumberLaTeX(number = upper - lower, digits = dig),
           p0 = formatNumberLaTeX(number = p0, digits = digPvals)
           ) |>
    select(labels, type, est, w1, ci, ciwidth, p0)
kable(RESPIREtab |> select(-labels),
      format = "latex", booktabs = TRUE, align = "lcccccc",
      col.names = c("",
                    "\\textbf{Log rate ratio}",
                    "\\textbf{Weight RESPIRE 1}",
                    "\\textbf{95\\% CI}",
                    "\\textbf{CI width}",
                    "\\textbf{\\textit{P}-value (one-sided)}"),
      bold = TRUE, escape = FALSE) |>
    pack_rows("14-day treatment group", 1, 8, escape = FALSE, bold = FALSE,
              italic = TRUE) |>
    pack_rows("28-day treatment group", 9, 16, escape = FALSE, bold = FALSE,
              italic = TRUE) |>
    row_spec(c(2, 10), hline_after = TRUE) |>
    row_spec(seq(1, nrow(RESPIREtab), by = 2), background = "#F0F0F0")
@
\end{table}

Looking at the combined point estimates, we can see that for both the 14-day and
28-day regimens, the estimate based on Tippett's method is the smallest (i.e.,
most anti-conservative for alternative = ``less''), while the estimate based on
the two-trials rule is the largest (i.e., the most conservative). A similar but
slightly attenuated pattern is seen for Fisher's (anti-conservative) and
Pearson's (conservative) methods, whereas the estimates from meta-analysis and
Edgington's method are almost identical and fall somewhere between the
individual trials' effect estimates. All point estimates are thus consistent
with the theoretically expected behavior of the methods.

It is interesting to consider the median estimate as a weighted average of the
trial specific point estimates, and to determine the corresponding (implicit)
weights. Table~\ref{tab:tabrespirecombined} reports the weight of the point
estimate from RESPIRE 1 toward the median estimate (the weight from RESPIRE 2 is
one minus the weight from RESPIRE 1).
%%  These weights were computed by solving $\hat{\mu}(1/2) = w\hat{\theta}_1 +
%% (1 - w) \hat{\theta}_2$ for the weight $w$.
It is visible that the more extreme estimate (RESPIRE 1 in the 14-day group, and
RESPIRE 2 in the 28-day group) contributes more to Tippett's and Fisher's
estimates and less to Pearson's and the two-trials rule estimates, which aligns
with the expected behavior. Similarly, the weight of RESPIRE 1 is slightly
larger for Edgington's method than meta-analysis because Edgington's estimate
gives more weights to trials with larger standard errors due to its inverse
standard error weighting.

Looking at the CIs, we can see that meta-analysis produces narrower CIs than the
other methods for both treatment regimens. The widest CIs are produced by
Edgington's method. For the 28-day regimen, Edgington's CI is the only method
that includes both trial effect estimates, and as a result is even wider than
the CIs from the individual trials, reflecting the apparent heterogeneity.
Looking at the decision based on the CIs, we can see that for the 14-day
regimens, all 95\% CIs exclude a log rate ratio of zero, the value of no effect,
while all \Sexpr{round(100*(1 - 2*0.025^2),3)}\% CIs include it. However, for
the 28-day regimens, the 95\% CIs from meta-analysis, Fisher's, and Tippett's
methods exclude zero. The other method's 95\% CIs include zero, but only
Edgington's method includes also the point estimate from RESPIRE~2. Finally, the
\Sexpr{round(100*(1 - 2*0.025^2),3)}\% CIs of all methods include zero, thus
leading to identical decisions at the one-sided $0.025^2 = \Sexpr{0.025^2}$
level. Note that for each method, the decision based on the CI is compatible
with the combined \textit{p}-values in Table~\ref{tab:tabrespirecombined}, for example,
a \Sexpr{round(100*(1 - 2*0.025^2),3)}\% CI excludes a log rate ratio of zero
only if also the combined one-sided \textit{p}-value is less than $\Sexpr{0.025^2}$.

\subsection{The ORBIT trials}
Another pair of clinical trials that investigated the effect of ciprofloxacin
are the ORBIT~3 and ORBIT~4 trials \citep{Haworth2019}. The trials assessed the
effect of inhaled liposomal ciprofloxacin compared to placebo in patients with
non-cystic fibrosis bronchiectasis and chronic lung infection with
\textit{Pseudomonas aeruginosa}. Like the RESPIRE trials, the ORBIT trials also
showed considerable heterogeneity. Figure~\ref{fig:ORBIT} shows \textit{p}-values,
point estimates, and CIs for the primary endpoint (time to the first
exacerbation; effect quantified with a log hazard ratio) and a secondary
endpoint (frequency of exacerbations; effect quantified with a log rate ratio).
Table~\ref{tab:taborbitcombined} gives numerical summaries.

\begin{figure}[!tb]
<< "ORBIT-analysis", fig.height = 5 >>=
## compute results for ORBIT trials
ORBITres <- resFun(t1 = c(loghr3, logrr3),
                   se1 = c(seloghr3, selogrr3),
                   t2 = c(loghr4, logrr4),
                   se2 = c(seloghr4, selogrr4),
                            # time to the first exacerbation
                   labels = c("Primary endpoint (log hazard ratio)",
                            # frequency of exacerbations
                              "Secondary endpoint (log rate ratio)"),
                   xlim = c(-0.8, 0.4),
                   alternative = "less", alpha = 0.05, null = 0,
                   lab1 = "ORBIT 3", lab2 = "ORBIT 4")
names(cols)[1:2] <- names(lty)[1:2] <- c("ORBIT 3", "ORBIT 4")

## ## save ORBIT results as CSV
## ORBITres$summariesDF |>
##         select(type, labels, lower, est, upper, p0, w1, w2) |>
##     rename(Type = type, Endpoint = labels, "Lower 95% CL" = lower,
##            "Point estimate" = est, "Upper 95% CL" = upper, "P-value" = p0,
##            "Weight ORBIT 3" = w1, "Weight ORBIT 4" = w2) |>
##     write.csv(file = "data/ORBIT.csv", row.names = FALSE)

## plot results
ggplot(data = ORBITres$pDF, aes(x = mu, y = p, color = type, linetype = type)) +
    facet_wrap(~ labels, ncol = 1) +
    geom_hline(yintercept = alpha, lty = "longdash", alpha = 0.1) +
    geom_line() +
    geom_pointrange(data = ORBITres$summariesDF,
                    aes(xmin = lower2, xmax = upper2, x = est, y = 1.15),
                    position = position_dodge2(width = 0.25), fatten = 0,
                    linewidth = 0.3, alpha = 0.3) +
    geom_pointrange(data = ORBITres$summariesDF,
                    aes(xmin = lower, xmax = upper, x = est, y = 1.15),
                    position = position_dodge2(width = 0.25),
                    fatten = 1.1) +
    ## geom_vline(data = ORBITres$summariesDF, aes(xintercept = upper, color = type),
    ##            alpha = 0.2) +
    ## geom_vline(data = ORBITres$summariesDF, aes(xintercept = lower, color = type),
    ##            alpha = 0.2) +
    scale_linetype_manual(values = lty, guide = guide_legend(reverse = TRUE)) +
    scale_color_manual(values = cols, guide = guide_legend(reverse = TRUE)) +
    coord_cartesian(xlim = c(-0.8, 0.4), ylim = c(-0.02, 1.25)) +
    scale_x_continuous(breaks = seq(-0.75, 0.5, 0.25)) +
    scale_y_continuous(breaks = c(seq(0.25, 1, 0.25), 0.05),
                       sec.axis = sec_axis(~ 1 - .,
                                           breaks = c(seq(0, 0.75, 0.25), 0.95),
                                           labels = scales::percent,
                                           name = "Confidence")) +
    annotate(geom = "segment", arrow = arrow(length = unit(1.2, 'mm'),
                                             type = "closed"),
             alpha = 0.6,
             x = c(-1, 1)*0.02, xend = c(-1, 1)*0.2,
             y = -0.06, yend = -0.06) +
    annotate(geom = "text", alpha = 0.8, label = "Benefit",
             x = -0.1, y = -0.025, size = 2.75) +
     annotate(geom = "text", alpha = 0.8, label = "Harm",
             x = 0.1, y = -0.025, size = 2.75) +
    labs(x = "Effect size", y = bquote(italic(p) * "-value"),
         color = NULL, linetype = NULL) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background = element_rect(fill = "#00000005"))
@
\caption{Results of the ORBIT trials \citep{Haworth2019} for the effect of
  ciprofloxacin in patients with non-cystic fibrosis bronchiectasis and chronic
  lung infection with \textit{Pseudomonas aeruginosa}. The two-sided \textit{p}-value
  functions of the individual trials (dashed lines), and the combined \textit{p}-value
  functions (solid lines) based on the two-trials rule, fixed-effect
  meta-analysis, Tippett's, Fisher's, Pearson's, and Edgington's methods are
  shown along with corresponding median estimates and CIs (95\% and
  \Sexpr{round(100*(1 - 2*0.025^2),3)}\% via telescope lines). All \textit{p}-values
  are based on the alternative "\Sexpr{input_p}" and then converted to two-sided
  \textit{p}-values via the centrality function $2\min\{p, 1 - p\}$.}
\label{fig:ORBIT}
\end{figure}

We see that there is substantial heterogeneity for the primary endpoint, with
the point estimate from ORBIT 3 close to zero ($\log\widehat{\mathrm{HR}} =
\Sexpr{round(loghr3, 2)}$ with 95\% CI from $\Sexpr{round(ciloghr3[1], 2)}$ to
$\Sexpr{round(ciloghr3[2], 2)}$), whereas the estimate from ORBIT 4 indicates a
more beneficial treatment effect ($\log\widehat{\mathrm{HR}} =
\Sexpr{round(loghr4, 2)}$ with 95\% CI from $\Sexpr{round(ciloghr4[1], 2)}$ to
$\Sexpr{round(ciloghr4[2], 2)}$). While the theoretically expected patterns of
the different median estimates and CIs are visible, the qualitative decisions
based on all the different combination methods are the same at both the $0.025$
and $0.025^2$ levels.

\begin{table}[!htb]
  \centering
  \caption{Point estimates (with implicit weights), 95\% CIs (with widths), and
    \textit{p}-values for the ORBIT trials \citep{Haworth2019}. Note that
    weigths and CI widths are computed from unrounded numbers and may not always
    exactly correspond with rounded point estimates and CIs.}
  \label{tab:taborbitcombined}
<< "table-ORBIT", results = "asis" >>=
ORBITtab <- ORBITres$summariesDF |>
    mutate(est = formatNumberLaTeX(number = est, digits = dig),
           w1 = formatNumberLaTeX(number = w1, digits = dig),
           ci = formatCILaTeX(lower = lower, upper = upper, digits = dig),
           ciwidth = formatNumberLaTeX(number = upper - lower, digits = dig),
           p0 = formatNumberLaTeX(number = p0, digits = digPvals)
           ) |>
    select(labels, type, est, w1, ci, ciwidth, p0)
kable(ORBITtab |> select(-labels),
      format = "latex", booktabs = TRUE, align = "lcccccc",
      col.names = c("",
                    "\\textbf{Log rate ratio}",
                    "\\textbf{Weight ORBIT 3}",
                    "\\textbf{95\\% CI}",
                    "\\textbf{CI width}",
                    "\\textbf{\\textit{P}-value (one-sided)}"),
      bold = TRUE, escape = FALSE) |>
    pack_rows("\\textit{Primary endpoint (log hazard ratio)}", 1, 8,
              escape = FALSE, bold = FALSE, italic = TRUE) |>
    pack_rows("\\textit{Secondary endpoint (log rate ratio)}", 9, 16,
              escape = FALSE, bold = FALSE, italic = TRUE) |>
    row_spec(c(2, 10), hline_after = TRUE) |>
    row_spec(seq(1, nrow(RESPIREtab), by = 2), background = "#F0F0F0")
@
\end{table}


Looking at the secondary endpoint, there is also considerable heterogeneity
between the results from ORBIT 3 ($\log\widehat{\mathrm{RR}} =
\Sexpr{round(logrr3, 2)}$ with 95\% CI from $\Sexpr{round(cilogrr3[1], 2)}$ to
$\Sexpr{round(cilogrr3[2], 2)}$) and ORBIT 4 ($\log\widehat{\mathrm{RR}} =
\Sexpr{round(logrr4, 2)}$ with 95\% CI from $\Sexpr{round(cilogrr4[1], 2)}$ to
$\Sexpr{round(cilogrr4[2], 2)}$) leading to some more noticeable qualitative
differences between the methods. That is, the \Sexpr{round(100*(1 -
  2*0.025^2),3)}\% CIs from meta-analysis and Fisher's method exclude a log rate
ratio of zero while the remaining methods include it, leading to different
decisions at the $0.025^2$ level. Again, Edgington's CI is much wider than the
others due to the substantial heterogeneity.

In summary, the analyses of the RESPIRE and ORBIT trials showed how combined
\textit{p}-value functions allow us to obtain point estimates, CIs, and
\textit{p}-values that are inherently compatible. They also showed that
different combination methods can lead to different inferences and decisions,
especially in the presence of between-trial heterogeneity, highlighting the need
to think about the estimand of interest.

\section{Extension to more than two trials}
\label{sec:extensions}
The methods discussed so far have focused on the setting where only two trials
are available, but in practice it may happen that investigators want to assess
the combined evidence from more than two trials. In this context, Rosenkranz
\citep{Rosenkranz2023} suggested that decision rules should maintain the type I
error rate of the two-trials rule for two studies $\alpha^2$, even if there are
more than two studies. This can be implemented using combined \textit{p}-value
functions, as all methods considered before can be generalized to more than two
trials \citep{XieSingh2013, Held_etal2024b}. A decision rule can then be based
on the combined one-sided \textit{p}-value for the null hypothesis of no effect
%% being less than $\alpha$
or a $(1 - 2\alpha^2)\times 100\%$ CI obtained from a combined \textit{p}-value
function. In addition, a point estimate and 95\% CI can be used to summarize the
combined evidence.


While all point estimates and confidence intervals in this setting can be
computed numerically, some of the analytical results derived earlier generalize
to more than two studies. Specifically, closed-form median estimates and
confidence intervals remain available for the two-trials rule, Tippett's method,
and meta-analysis, whereas such closed-form solutions are not available for
Fisher's, Pearson's, and Edgington's methods \citep{Held_etal2024b}. In
particular, for Edgington's method, one might expect the median
estimate~\eqref{eq:edgingtonpointest} to generalize by incorporating additional
effect estimates with inverse standard error weights. However, a comparison with
numerically computed median estimates showed that this is not the case. Thus,
the inverse standard error weighted average in~\eqref{eq:edgingtonpointest}
corresponds to Edgington's median estimate only in the setting of two trials.

Figure~\ref{fig:respireall} shows \textit{p}-value functions that combine all
four results from the two RESPIRE trials, as also done by Chotirmall and
Chalmers \citep{Chotirmall2018} with fixed-effect meta-analysis. Looking at the
median estimates, we see the same patterns as when the methods are applied to
only two trials; The median estimates from meta-analysis and Edgington's method
are somewhere in between the trials' individual estimates. The median estimates
based on Fisher's and Tippett's method are the most anti-conservative, and the
median estimates based on Pearson's method and the two-trials rule are the most
conservative. A decision rule that maintains the $\alpha^2 = 0.025^2$ type I
error rate of the two trials rule could now be defined by flagging drug efficacy
when the $(1 - 2\alpha^2) \times 100\% = 99.875\%$ excludes the null value.
Following this rule, we can see that Fisher's method and meta-analysis flag
efficacy while the remaining methods do not. In sum, this example illustrates
how combined \textit{p}-value functions can be applied to more than two trials,
while allowing to maintain the same type I error rate as for two trials.

\begin{figure}[!htb]
<< "more-than-2-trials", fig.height = 3 >>=
## parameters
museq <- seq(-1, 0.5, length.out = 5000)
input_p <- "less"
alpha <- 0.05
null <- 0

## all RESPIRE trials
lower <- c(cilogrr14r1[1], cilogrr28r1[1],
           cilogrr14r2[1], cilogrr28r2[1])
upper <- c(cilogrr14r1[2], cilogrr28r1[2],
           cilogrr14r2[2], cilogrr28r2[2])
labels <- c("RESPIRE 1 14-day", "RESPIRE 1 28-day",
            "RESPIRE 2 14-day", "RESPIRE 2 28-day")
est <- c(logrr14r1, logrr28r1, logrr14r2, logrr28r2)
se <- c(selogrr14r1, selogrr28r1, selogrr14r2, selogrr28r2)
lower2 <- NA # est - se*qnorm(p = 1 - (alpha/2)^2)
upper2 <- NA # est + se*qnorm(p = 1 - (alpha/2)^2)

## compute combined p-value functions
funs <- list("Two-trials rule" = p_wilkinson,
             "Tippett" = p_tippett,
             "Pearson" = p_pearson,
             "Edgington" = p_edgington,
             "Fisher" = p_fisher,
             "Meta-analysis" = p_stouffer)
resList <- lapply(X = seq(1, length(funs)), FUN = function(i) {
    fun <- funs[[i]]
    if (names(funs)[i] != "Meta-analysis") {
        pvals <- fun(estimates = est, SEs = se, mu = museq, input_p = input_p)
        cm <- confMeta(estimates = est, SEs = se, fun = fun, input_p = input_p)
        pointest <- cm$p_max[1]
        lower1 <- cm$joint_cis[1]
        upper1 <- cm$joint_cis[2]
        ## HACK manually compute the 99.875% CIs
        ## some issues in confMeta
        ## cm2 <- confMeta(estimates = est, SEs = se, fun = fun, input_p = input_p,
        ##                 conf_level = 1 - 2*(alpha/2)^2)
        rootFun <- function(mu) {
            fun(estimates = est, SEs = se, mu = mu, input_p = input_p) -
                2*(alpha/2)^2
        }
        lower2 <- uniroot(f = rootFun, interval = c(-2, pointest))$root
        upper2 <- uniroot(f = rootFun, interval = c(pointest, 2))$root
    } else {
        semeta <- 1/sqrt(sum(1/se^2))
        pointest <- sum(est/se^2)*semeta^2
        pvals <- 2*(1 - pnorm(q = abs(pointest - museq)/semeta))
        ci1 <- pointest + c(-1, 1)*qnorm(p = 0.975)*semeta
        lower1 <- ci1[1]
        upper1 <- ci1[2]
        ci2 <- pointest + c(-1, 1)*qnorm(p = 1 - (alpha/2)^2)*semeta
        lower2 <- ci2[1]
        upper2 <- ci2[2]
    }
    summariesDF <- data.frame(method = names(funs)[i], lower = lower1,
                              estimate = pointest, upper = upper1,
                              lower2 = lower2, upper2 = upper2)
    pDF <- data.frame(method = names(funs)[i], mu = museq, p = pvals)
    return(list("summaries" = summariesDF, "p" = pDF))
})
summariesDF <- rbind(data.frame(method = labels, lower = lower, estimate = est,
                                upper = upper, lower2 = lower2, upper2 = upper2),
                     do.call("rbind",
                             lapply(X = resList, FUN = function(x) x$summaries)))
pDF <- rbind(do.call("rbind",
                     lapply(X = seq(1, length(est)), FUN = function(i) {
                         data.frame(method = labels[i], mu = museq,
                                    p = 2*(1 - pnorm(abs(est[i] - museq)/se[i])))
                     })),
             do.call("rbind", lapply(X = resList, FUN = function(x) x$p)))
typelevels <- c("RESPIRE 1 14-day", "RESPIRE 2 14-day",
                "RESPIRE 1 28-day", "RESPIRE 2 28-day",
                "Two-trials rule", "Meta-analysis", "Tippett", "Fisher",
                 "Pearson", "Edgington")
summariesDF$method <- factor(summariesDF$method, levels = rev(typelevels))
pDF$method <- factor(pDF$method, levels = rev(typelevels))

## plot them
cols <- c("RESPIRE 1 14-day" = "#CC79A7E6", "RESPIRE 2 14-day" = "#CC79A7E6",
          "RESPIRE 1 28-day" = "#888888E6", "RESPIRE 2 28-day" = "#888888E6",
          "Meta-analysis" = "#56B4E9F2", "Two-trials rule" = "#000000F2",
          "Tippett" = "#E69F00F2", "Edgington" = "#009E73F2",
          "Fisher" = "#F0E442F2", "Pearson" = "#0072B2F2")
lty <- c("dashed", "dotted", "dashed", "dotted", rep("solid", 6))
names(lty) <- names(cols)
ggplot(data = pDF, aes(x = mu, y = p, color = method, linetype = method)) +
    geom_hline(yintercept = alpha, lty = "longdash", alpha = 0.1) +
    geom_line() +
    geom_pointrange(data = summariesDF,
                    aes(xmin = lower2, xmax = upper2, x = estimate, y = 1.15),
                    position = position_dodge2(width = 0.25), fatten = 0,
                    linewidth = 0.3, alpha = 0.3) +
    geom_pointrange(data = summariesDF,
                    aes(xmin = lower, xmax = upper, x = estimate, y = 1.15),
                    position = position_dodge2(width = 0.25),
                    fatten = 1.1) +
    scale_linetype_manual(values = lty, guide = guide_legend(reverse = TRUE)) +
    scale_color_manual(values = cols, guide = guide_legend(reverse = TRUE)) +
    coord_cartesian(xlim = range(museq), ylim = c(-0.02, 1.25)) +
    scale_x_continuous(breaks = round(seq(-0.9, 0.3, 0.3), 1)) +
    scale_y_continuous(breaks = c(seq(0.25, 1, 0.25), 0.05),
                       sec.axis = sec_axis(~ 1 - .,
                                           breaks = c(seq(0, 0.75, 0.25), 0.95),
                                           labels = scales::percent,
                                           name = "Confidence")) +
    annotate(geom = "segment", arrow = arrow(length = unit(1.2, 'mm'),
                                             type = "closed"),
             alpha = 0.6,
             x = c(-1, 1)*0.02, xend = c(-1, 1)*0.2,
             y = -0.06, yend = -0.06) +
    annotate(geom = "text", alpha = 0.8, label = "Benefit",
             x = -0.1, y = -0.025, size = 2.75) +
    annotate(geom = "text", alpha = 0.8, label = "Harm",
             x = 0.1, y = -0.025, size = 2.75) +
    labs(x = "Log rate ratio", y = bquote(italic(p) * "-value"),
         color = NULL, linetype = NULL) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background = element_rect(fill = "#00000005"))

## ## does Edgington's median estimate generalize to more than 2 studies?
## ## No! not the same
## subset(summariesDF, method == "Edgington")$estimate # -0.328873
## sum(est/se)/sum(1/se) # -0.3238609
@
\caption{Combined \textit{p}-value function based on combining all four estimates from
  the RESPIRE trials \citep{Aksamit2018, DeSoyza2018, Chotirmall2018} along with
  corresponding median estimates and CIs (95\% and 99.875\% via telescope
  lines).}
\label{fig:respireall}
\end{figure}


\section{Discussion}
\label{sec:discussion}
The two-trials rule has been widely discussed in the literature but discussions
have mostly focused on hypothesis testing characteristics, such as power or type
I error rate \citep{Fisher1999, Fisher1999b, Lu2001, Rosenkranz2002, Maca2002,
  Shao2002, Shun2005, vanRavenzwaaij2017, kennedySchaffer:2017, Senn2021,
  Zhan2022, Rosenkranz2023, Held2024}. In this paper, we took a different
perspective, systematically examining the two-trials rule and alternative
methods in terms of effect estimation. By casting them in a combined \textit{p}-value
function framework, we derived compatible \textit{p}-values, confidence intervals, and
point estimates. These quantities are compatible in the sense that the two-sided
\textit{p}-value for a null value is less than $\alpha$ if and only if the null value
is excluded by the $(1 - \alpha) \times 100\%$ CI, and that the point estimate
is contained in the CI at any confidence level. While meta-analytic effect
estimates, CIs, and \textit{p}-values have been well studied, our novel results enable
computation of CIs and effect estimates based on the two-trials rule.
Investigators could therefore report not only individual trial \textit{p}-values
(essentially the two-trials rule) and meta-analytic estimates but also point
estimates and CIs based on the two-trials rule.

Our findings also clarify how different \textit{p}-value combination methods
implicitly target different estimands. Reassuringly, under effect homogeneity
(i.e., the same true effect in both trials), all methods yield consistent point
estimates and CIs that shrink toward the true effect as standard errors
decrease, although some show bias. Theoretically, meta-analysis has the smallest
variance among all unbiased estimators (attaining the Cramér-Rao lower bound)
and may be preferred. However, under effect heterogeneity -- arguably the more
realistic scenario -- it is less clear which method should be recommended. The
two-trials rule and Pearson's method are conservative (targeting the less
extreme effect), Fisher's and Tippett's methods are anti-conservative (targeting
the more extreme effect), while Edgington's method and meta-analysis are
balanced (targeting a weighted average). This raises an important question: What
kind of effect is of scientific interest when the true trial effects differ? If
the investigators are interested in the less extreme effect -- arguably a
sensible choice when the effects relate to a medical treatment with potential
side effects -- then the two-trials rule and Pearson's method seem reasonable.
On the other hand, a weighted average effect, as targeted by meta-analysis and
Edgington's method, might be a relevant estimand if it is representative for a
larger population \citep{Rice_etal2018}. Finally, the more extreme effect might
be the relevant estimand if the maximum achievable benefit of a treatment is of
scientific interest, in which case Tippett's and Fisher's methods might be
reasonable choices. %% While the conclusion that no single method is always
%% appropriate may seem unsatisfying, it aligns with the
This parallels the findings of Heard and Rubin-Delanchy \citep{Heard2018}, who
showed that many \textit{p}-value combination methods are equivalent to a
likelihood ratio test for specific alternative hypotheses. This means that each
such method can be most powerful under certain conditions. Therefore,
researchers must carefully reflect which alternative hypothesis is most relevant
to their application -- just as they need to reflect on choosing an appropriate
estimand -- to select a suitable combination method.

Beyond theoretical considerations, practical issues must be addressed. A major
concern is that if the effect estimates from both trials are the same, the
two-trials rule, Tippett's, Fisher's, and Pearson's methods all produce
counterintuitive effect estimates that differ from the one observed in both
trials. Such point estimates are unintuitive and difficult to communicate to
non-statisticians. Moreover, only Edgington's method and meta-analysis produce
the same combined estimate and two-sided confidence interval in case the
alternative of combined $p$-values is changed \citep{Held_etal2024b}, which
seems another practically desired property. From this perspective, Edgington's
method and meta-analysis may be preferable. In particular, Edgington's method
can also account for effect heterogeneity by widening its CI when there is
heterogeneity and asymptotically always includes both effects. However, this is
traded off with a less efficient median estimate under effect homogeneity, whose
standard error can even be larger than those from both trials if they greatly
differ. Finally, another practical challenge is aligning decisions based on a
one-sided combined \textit{p}-value thresholded at $\alpha^2$ with two-sided
CIs. This requires using a $(1 - 2\alpha^{2})\times 100\%$ confidence level.
However, in many fields, researchers are not used to such confidence levels, so
we suggest to report both a more conventional level (e.g., 95\%) along with $(1
- 2\alpha^{2}) \times 100\%$ via telescope-style CIs, as well as the underlying
\textit{p}-value function, as in
Figures~\ref{fig:twinstudies}--\ref{fig:respireall}. The idea of telescope-style
CIs is not new but has been suggested before in different contexts
\citep{Louis2008}.

A broader issue is the question of whether two trials are actually necessary. If
the designs of the two trials are so similar that they can be considered
exchangeable (``direct replications'' \citep{Nosek2017b}), there are various
arguments in favor of conducting one large trial instead of two smaller ones
\citep{Fisher1999,Senn2021}. Also our study demonstrates that having two trials
instead of one makes estimation more complicated. Conversly, if the trial
designs differ significantly (``conceptual replications'' \citep{Nosek2017b},
e.g., if they use different endpoints or populations), achieving success in both
trials may provide more robust evidence of treatment efficacy. From this
perspective, it is sensible to design the trials differently to some extent
\citep{Senn2021}. However, there is perhaps a limit to how different the trials
can be, as when there is too much heterogeneity, combining the effect estimates
into a single number would no longer be meaningful.
%% However, in practice sponsors often do the opposite and run two almost
%% identical trials, which one could argue diminishes the logical justification
%% of the two-trials rule to some extent \citep[Section 12.2.8]{Senn2021}.



Our results have broader implications beyond the two-trial setting. Methods for
combining \textit{p}-values are also used in adaptive trials, where they enable
combination of stage-wise \textit{p}-values \citep{Bauer1994, Lehmacher1999,
  Bauer1999}. Combined \textit{p}-value functions can be generalized to more
than two studies, making them applicable to meta-analysis \citep{XieSingh2013,
  Held_etal2024b}. They can also be applied to replication and real-world
evidence studies, where the two-trials rule (under different names such as
significance criterion or vote-counting) is used to assess the replicability of
original findings \citep{Bartlett2019, Wang2022, Held_etal2024}. In all these
scenarios, we may consider combined \textit{p}-value functions for parameter
estimation, but in each application researchers must also decide which
combination method has the statistical properties to estimate the scientific
effect of interest. Future research may also examine other combination methods
beyond the ones considered here, such as the inverse chi-square method
\citep{Lancaster1961, HedgesOlkin1985}, the harmonic mean $\chi^2$ test
\citep{Held2020b}, the Cauchy combination test \citep{Liu2019}, random-effects
meta-analysis \citep{Borenstein2010}, and combining \textit{p}-value functions
that are based on the exact distribution of the data rather than normality
\citep[e.g., the \textit{p}-value function based on Fisher's exact test with
  mid-\textit{p} correction as considered in ][]{Schweder2013, Held_etal2024b}.
Additionally, fixed-effect meta-analysis has a Bayesian interpretation,
corresponding to posterior inferences assuming equal true study effects and a
flat prior distribution. Investigating whether other \textit{p}-value
combination methods have similar Bayesian justifications could be an interesting
avenue for future work. To sum up, combined \textit{p}-value functions provide a
unified approach for combining results from two trials that can be further
developed theoretically. Moreover, our software implementation allows
researchers to conveniently apply these methods in practice.

\bmsection*{Acknowledgments}

We thank the editor, associate editor, Stephen Senn, and another anonymous
reviewer for valuable comments that led to numerous additions and improvements.
The acknowledgment of these individuals does not imply their endorsement of the
paper.

\bmsection*{Conflict of interest}
We declare no conflict of interest.

\bmsection*{Software and data} Data from the RESPIRE trials were extracted from
Table~3 in De Soyza et al. \citep{DeSoyza2018} and Table~3 in Aksamit et al.
\citep{Aksamit2018}. Data from the ORBIT trials were extracted from page~219 in
Haworth et al. \citep{Haworth2019}. Code and data to reproduce all numbers,
tables, and figures are openly available at
\url{https://github.com/SamCH93/twotrials}. Spreadsheets containing the numbers
from Tables~\ref{tab:tabrespirecombined} and~\ref{tab:taborbitcombined} with
higher precision are also available at the repository. A snapshot of the
repository at the time of writing is available at
\url{https://doi.org/10.5281/zenodo.15017483}. We used the statistical
programming language \Sexpr{R.Version()[["version.string"]]} for analyses
\citep{R} along with the \texttt{confMeta} \citep{confMeta2024},
\texttt{ggplot2} \citep{Wickham2016}, \texttt{kableExtra} \citep{Zhu2024},
\texttt{dplyr} \citep{Wickham2023}, and \texttt{knitr} \citep{Xie2015} packages.

\bibliography{bibliography.bib}

\appendix

\bmsection{The R package twotrials}
\label{app:rpackage}
We have developed the \texttt{twotrials} R package for easily conducting
combined \textit{p}-value function inference based on the parameter estimates
(with standard errors) from two trials. The package can be installed from the
Comprehensive R Archive Network (CRAN) via the R command
\texttt{install.packages("twotrials")}.

For every \textit{p}-value combination method discussed in this paper, the package
provides a combined \textit{p}-value function (e.g., \texttt{pEdgington}) and a
combined estimation function (e.g., \texttt{muEdgington}). While these can be
used to manually compute \textit{p}-values and parameter estimates, the convenience
function \texttt{twotrials} automatically computes estimates and \textit{p}-values
based on all methods, and allows for easy printing and plotting of the results.
The following code chunk illustrates its usage by reproducing the results for
the 14-day treatment group from Table~\ref{tab:tabrespirecombined}.

<< "R-package-illustration", echo = TRUE, fig.height = 3.5, size = "scriptsize" >>=
library(twotrials) # load package

## combine logRR estimates from RESPIRE trials
results <- twotrials(null = 0, t1 = -0.4942, t2 = -0.1847, se1 = 0.1833,
                     se2 = 0.1738, alternative = "less", level = 0.95)
print(results, digits = 2) # print summary of results
@

Note that, for each combined estimate, the function also returns the weights
$w_1$ (\texttt{W1}) and $w_2$ (\texttt{W2}). These represent the implicit linear
weights of the point estimates from trials 1 and 2 towards the combined
estimate, i.e., $\hat{\mu}(1/2) = w_1 \hat{\theta}_1 + w_2 \hat{\theta}_2$. Such
weights aid interpretation by indicating how close each trial estimate is to the
combined estimate. Finally, applying the plot function to the resulting object
makes it easy to display the combined \textit{p}-value functions, as
demonstrated below.

<< "R-package-illustration2", echo = TRUE, fig.height = 3.5, size = "scriptsize" >>=
plot(results, xlim = c(-1, 0.5), two.sided = TRUE) # plot p-value functions
@

\bmsection{Technical details}
\label{app:technicaldetails}
This appendix contains technical details on the derivation of results from the
main paper.


\bmsubsection{Expectation of the combined estimation function}
\label{app:expectation}
Consider the random variables
\begin{align}
  \label{eq:XandY}
  &X = \min\{\hat{\theta}_1 + \sigma_1 \, q, \hat{\theta}_2 + \sigma_2 \, q\}&
   &\text{and}&
  &Y = \max\{\hat{\theta}_1 - \sigma_1 \, q, \hat{\theta}_2 - \sigma_2 \, q\}.&
\end{align}
Table~\ref{tab:constant} shows that for certain choices of the constant $q$, $X$
and $Y$ are equal to the combined estimation functions from the two-trials
rule~\eqref{eq:2trialsest} and Tippett's method~\eqref{eq:tippest} in the main
paper, and the approximate combined estimation functions from
Fisher's~\eqref{eq:fisherest2}, Pearson's~\eqref{eq:pearsonest2}, and
Edgington's methods~\eqref{eq:edgingtonprecise} and~\eqref{eq:edgingtonprecise2}
discussed below. Note that for Edgington's method (with $a = 1/2$) and
meta-analysis, the distribution of the combined estimation function is normal
and its expectation is therefore known and need not be derived here.

\begin{table}[!htb]
  \centering

  \caption{Constants $q$ for which $X$ or $Y$ are equal to the combined
    estimation function of a specific method.}
  \label{tab:constant} \rowcolors{1}{}{gray!15}

  \begingroup
  \renewcommand{\arraystretch}{1.3}
  \begin{tabular}{l l l}
    \toprule
    \multicolumn{1}{c}{\textbf{Method}} & \multicolumn{1}{c}{\textbf{Alternative ``greater''}} & \multicolumn{1}{c}{\textbf{Alternative ``less''}} \\

    \midrule
    Two-trials rule & $X$ with $q = z_{\sqrt{a}}$ & $Y$ with $q = z_{\sqrt{a}}$\\

    Tippett & $Y$ with $q = z_{\sqrt{1 - a}}$ & $X$ with $q = z_{\sqrt{1 - a}}$\\

    Fisher (approximate) & $Y$ with $q = -z_{\exp\{-\chi^2_4(1 - a)/2\}}$ & $X$ with $q = -z_{\exp\{-\chi^2_4(1 - a)/2\}}$ \\

    Pearson (approximate) & $X$ with $q = -z_{\exp\{-\chi^2_4(a)/2\}}$ & $Y$ with $q = -z_{\exp\{-\chi^2_4(a)/2\}}$ \\

    Edgington (approximate, $a < 1/2$) & $X$ with $q = z_{\sqrt{2a}}$ & $Y$ with $q = -z_{\sqrt{2a}}$ \\

    Edgington (approximate, $a > 1/2$) & $Y$ with $q = -z_{\sqrt{2(1 - a)}}$ & $X$ with $q = z_{\sqrt{2(1 - a)}}$ \\
    \bottomrule
  \end{tabular}
  \endgroup
\end{table}

According to the assumptions stated at the beginning of
Section~\ref{sec:combinedp}, $\hat{\theta}_1$ and $\hat{\theta}_2$ are
independent normal random variables with means $\theta_1, \theta_2$ and
variances $\sigma_1^2,\sigma_2^2$. We can therefore use the results from
Nadarajah and Kotz \citep{Nadarajah2008} on closed-form expressions for the
moments of minima and maxima of bivariate Gaussian random vectors. That is,
using their equations (9) and (11), it can be shown that the expectations of $X$
and $Y$ are given by
\begin{align*}
  E(X) =&
  (\theta_1 + \sigma_1 \, q) \times \Phi\left(\frac{\theta_2 - \theta_1 + q (\sigma_2 - \sigma_1)}{\sqrt{\sigma_1^2 + \sigma_2^2}}\right)
  + (\theta_2 + \sigma_2 \, q) \times \Phi\left(\frac{\theta_1 - \theta_2 + q (\sigma_1 - \sigma_2)}{\sqrt{\sigma_1^2 + \sigma_2^2}}\right)  \\
  &- \sqrt{\sigma_1^2 + \sigma_2^2} \times \phi\left(\frac{\theta_2 - \theta_1 + q (\sigma_2 - \sigma_1)}{\sqrt{\sigma_1^2 + \sigma_2^2}}\right)
\end{align*}
and
\begin{align*}
  E(Y) =&
  (\theta_1 - \sigma_1 \, q) \times \Phi\left(\frac{\theta_1 - \theta_2 + q (\sigma_2 - \sigma_1)}{\sqrt{\sigma_1^2 + \sigma_2^2}}\right)
  + (\theta_2 - \sigma_2 \, q) \times  \Phi\left(\frac{\theta_2 - \theta_1 + q (\sigma_1 - \sigma_2)}{\sqrt{\sigma_1^2 + \sigma_2^2}}\right) \\
  &+ \sqrt{\sigma_1^2 + \sigma_2^2} \times \phi\left(\frac{\theta_1 - \theta_2 + q (\sigma_2 - \sigma_1)}{\sqrt{\sigma_1^2 + \sigma_2^2}}\right),
\end{align*}
respectively. The expectation of the combined estimation function from a
specific method are thus obtained by setting the constant $q$ to the
corresponding value. For example, the expectation of the median estimate ($a =
1/2$) from the two-trials rule with alternative ``greater'' and $\sigma_1 =
\sigma_2 = \sigma$ in equation~\eqref{eq:exp2tr} is obtained from $E(X)$ with $q
= z_{\sqrt{1/2}}$.


\bmsubsection{Median estimate standard errors}
\label{app:ses}
Since the median estimates from meta-analysis and Edgington's method are simple
linear combinations of the trial effect estimates, their standard errors can be
straightforwardly derived to be
\begin{align*}
  &\sigma_{\text{MA}} %% \sqrt{\mathrm{Var}[\hat{\mu}_{\text{MA}}(1/2)]}
  = \frac{1}{\sqrt{1/\sigma^2_1 + 1/\sigma^2_2}}& &\text{and}& &\sigma_{\text{E}} %% \sqrt{\mathrm{Var}[\hat{\mu}_{\text{E}}(1/2)]}
  = \frac{\sqrt{2}}{1/\sigma_1 + 1/\sigma_2}.&
\end{align*}
By applying algebraic manipulations to $\sigma_{\text{MA}} \leq
\sigma_{\text{E}}$, one can see that the meta-analytic standard error is never
larger than Edgington's standard error, with equality if and only if the trial
standard error coincide ($\sigma_1 = \sigma_2$). Similarly, by applying
algebraic manipulations to $\sigma_{\text{E}} \leq \sigma_1$ and
$\sigma_{\text{E}} \leq \sigma_2$, one can see that Edgington's standard error
is only equal or smaller than either trial standard error if $\sqrt{2} - 1 \leq
\sigma_2/\sigma_1 \leq 1/(\sqrt{2} - 1) = \sqrt{2} + 1$.

For the remaining methods, the (approximate) median estimates are given by $X$
and $Y$ in equation~\eqref{eq:XandY} with $a = 1/2$. We can therefore use the
results from Nadarajah and Kotz \citep{Nadarajah2008} to obtain their second
moments
\begin{align*}
  E(X^2) =&
  \{\sigma^2_1 + (\theta_1 + \sigma_1\,q)^2\}\, \Phi\left(\frac{\theta_2 - \theta_1 + q(\sigma_2 - \sigma_1)}{\sqrt{\sigma^2_1 + \sigma^2_2}}\right) +
  \{\sigma^2_2 + (\theta_2 + \sigma_2\,q)^2\} \, \Phi\left(\frac{\theta_1 - \theta_2 + q(\sigma_1 - \sigma_2)}{\sqrt{\sigma^2_1 + \sigma^2_2}}\right) \\
  & -
  \{\theta_1 + \theta_2 + q(\sigma_1 + \sigma_2)\} \sqrt{\sigma_1^2 + \sigma_2^2} \, \phi\left(\frac{\theta_2 - \theta_1 + q(\sigma_2^2 - \sigma_1^2)}{\sqrt{\sigma_1 + \sigma_2}}\right)
\end{align*}
and
\begin{align*}
  E(Y^2) =&
  \{\sigma^2_1 + (\theta_1 - \sigma_1\,q)^2\}\, \Phi\left(\frac{\theta_1 - \theta_2 + q(\sigma_2 - \sigma_1)}{\sqrt{\sigma^2_1 + \sigma^2_2}}\right) +
  \{\sigma^2_2 + (\theta_2 - \sigma_2\,q)^2\} \, \Phi\left(\frac{\theta_2 - \theta_1 + q(\sigma_1 - \sigma_2)}{\sqrt{\sigma^2_1 + \sigma^2_2}}\right) \\
  & +
  \{\theta_1 + \theta_2 - q(\sigma_1 + \sigma_2)\} \sqrt{\sigma_1^2 + \sigma_2^2} \, \phi\left(\frac{\theta_1 - \theta_2 + q(\sigma_2 - \sigma_1)}{\sqrt{\sigma_1^2 + \sigma_2^2}}\right)
\end{align*}
and corresponding standard errors.
%% by subtracting the squared expectation followed by taking the square root.
For example, assuming equal standard errors ($\sigma_1 = \sigma_2 = \sigma$),
equal true effects ($\theta_1 = \theta_2 = \theta$) and the alternative
``greater'', the standard error of the two-trials rule median estimate ($X$ with
$q = z_{\sqrt{1/2}}$) simplifies to~\eqref{eq:se2tr}.
%% \begin{align*}
%%   \sigma_{\text{2TR}}
%%   = \sqrt{E(X^2) - E(X)^2}
%%   %% &=
%%   %% \sqrt{\sigma^2 + (\theta + \sigma z_{\sqrt{1/2}})^2 -
%%   %% \frac{2\sigma(\theta + \sigma z_{\sqrt{1/2}})}{\sqrt{\pi}}
%%   %% - \{\theta + \sigma (z_{\sqrt{1/2}} - 1/\sqrt{\pi})\}^2}
%%   %% %% many painful simplifications ...
%%   = \sigma \, \sqrt{1 - 1/\pi} \approx \sigma \times \Sexpr{round(sqrt(1 - 1/pi), 2)}.
%% \end{align*}

Figure~\ref{fig:ses} shows the standard errors from the median estimates of the
two-trials rule, meta-analysis, Tippett's, and Edgington's methods for various
scenarios of true trial effects and trial standard errors that should resemble
typical ranges for standardized mean difference parameters. The standard errors
from Fisher's and Pearson's methods are very close to the ones from Tippett's
method and the two-trials rule, and therefore not shown to make the plot easier
to read.


\begin{figure}[!htb]
<< "standard-errors-comparison", fig.height = 5 >>=
seMA <- function(se1, se2, ...) {
    1/sqrt(1/se1^2 + 1/se2^2)
}
seE <- function(se1, se2, ...) {
    sqrt(2)/(1/se1 + 1/se2)
}

## first and second moment of a random variable
## Y = max(hat(theta)_1 - q*se1, hat(theta)_2 - q*se2)
EY <- function(se1, se2, q, t1, t2) {
    (t1 - se1*q)*
        pnorm((t1 - t2 + q*(se2 - se1))/sqrt(se1^2 + se2^2)) +
        (t2 - se2*q)*
        pnorm((t2 - t1 + q*(se1 - se2))/sqrt(se1^2 + se2^2)) +
        sqrt(se1^2 + se2^2)*
        dnorm((t1 - t2 + q*(se2 - se1))/sqrt(se1^2 + se2^2))
}
EY2 <- function(se1, se2, q, t1, t2) {
    (se1^2 + (t1 - se1*q)^2)*
        pnorm((t1 - t2 + q*(se2 - se1))/sqrt(se1^2 + se2^2)) +
        (se2^2 + (t2 - se2*q)^2)*
        pnorm((t2 - t1 + q*(se1 - se2))/sqrt(se1^2 + se2^2)) +
        (t1 + t2 - q*(se1 + se2))*sqrt(se1^2 + se2^2)*
        dnorm((t1 - t2 + q*(se2 - se1))/sqrt(se1^2 + se2^2))
}

## first and second moment of a random variable
## X = min(hat(theta)_1 + q*se1, hat(theta)_2 + q*se2)
EX <- function(se1, se2, q, t1, t2) {
    (t1 + se1*q)*
        pnorm((t2 - t1 + q*(se2 - se1))/sqrt(se1^2 + se2^2)) +
        (t2 + se2*q)*
        pnorm((t1 - t2 + q*(se1 - se2))/sqrt(se1^2 + se2^2)) -
        sqrt(se1^2 + se2^2)*
        dnorm((t2 - t1 + q*(se2 - se1))/sqrt(se1^2 + se2^2))
}
EX2 <- function(se1, se2, q, t1, t2) {
    (se1^2 + (t1 + se1*q)^2)*
        pnorm((t2 - t1 + q*(se2 - se1))/sqrt(se1^2 + se2^2)) +
        (se2^2 + (t2 + se2*q)^2)*
        pnorm((t1 - t2 + q*(se1 - se2))/sqrt(se1^2 + se2^2)) -
        (t1 + t2 + q*(se1 + se2))*sqrt(se1^2 + se2^2)*
        dnorm((t2 - t1 + q*(se2 - se1))/sqrt(se1^2 + se2^2))
}

se2TR <- function(se1, se2, t1, t2, alternative = "greater") {
    q <- qnorm(p = sqrt(0.5))
    if (alternative == "greater") {
        sqrt(EX2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EX(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    } else {
        sqrt(EY2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EY(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    }
}
seT <- function(se1, se2, t1, t2, alternative = "greater") {
    q <- qnorm(p = sqrt(0.5))
    if (alternative == "greater") {
        sqrt(EY2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EY(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    } else {
        sqrt(EX2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EX(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    }
}
seF <- function(se1, se2, t1, t2, alternative = "greater") {
    ## only approximately valid when t1 != t2
    q <- -qnorm(p = exp(-qchisq(p = 0.25, df = 4)))
    if (alternative == "greater") {
        sqrt(EY2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EY(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    } else {
        sqrt(EX2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EX(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    }
}
seP <- function(se1, se2, t1, t2, alternative = "greater") {
    ## only approximately valid when t1 != t2
    q <- -qnorm(p = exp(-qchisq(p = 0.25, df = 4)))
    if (alternative == "greater") {
        sqrt(EX2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EX(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    } else {
        sqrt(EY2(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2) -
             EY(se1 = se1, se2 = se2, q = q, t1 = t1, t2 = t2)^2)
    }
}


## se1 <- 0.05
## se2 <- 0.1
## theta1 <- 0.45
## theta2 <- 0.5

## ## computing standard errors with simulation
## nsim <- 10000
## set.seed(42)
## t1 <- rnorm(n = nsim, mean = theta1, sd = se1)
## t2 <- rnorm(n = nsim, mean = theta2, sd = se2)
## simres <- do.call("rbind", lapply(X = seq_len(nsim), FUN = function(i) {
##     res <- twotrials(t1 = t1[i], t2 = t2[i], se1 = se1, se2 = se2)
##     data.frame(sim = i, res$summaries[,c("method", "est")])
## }))

## simSE <- tapply(simres$est, simres$method, FUN = sd)
## ## comparing to analytical standard errors
## aSE <- sapply(X = list("Edgington" = seE, "Fisher" = seF,
##                        "Meta-analysis" = seMA, "Pearson" = seP, "Tippett" = seT,
##                        "Two-trials rule" = se2TR),
##               FUN = function(f) f(se1 = se1, se2 = se2, t1 = theta1, t2 = theta2))
## signif(cbind(simSE, aSE), 4)

## ## checking simplified formula for 2TR
## se <- 1
## theta <- 0.5
## q <- qnorm(sqrt(0.5))
## se2TR(se1 = se, se2 = se, t1 = theta, t2 = theta)
## ## first simplification
## sqrt(se^2 + (theta + se*q)^2 - 2*se*(theta + se*q)/sqrt(pi) -
##      (theta + se*(q - 1/sqrt(pi)))^2)
## ## next simplification
## sqrt(se^2 + theta^2 + 2*theta*se*q + se^2*q^2 - 2*se*theta/sqrt(pi) - 2*se^2*q/sqrt(pi) - theta^2 - 2*theta*se*(q - 1/sqrt(pi)) - se^2*(q - 1/sqrt(pi))^2)
## ## next simplification
## sqrt(se^2*(1 - 1/pi))

## evaluate SEs over a grid of parameter values
n1 <- 200
se1 <- sqrt(2/n1)
rse <- c(0.33, 0.5, 1, 1.5, 3) # relative standard error
se2 <- se1*rse
nsim <- 10000
t <- c(0, 0.5, 1)
grid <- expand.grid(se1 = se1, se2 = se2, t1 = t, t2 = t)

## estimate SEs with simulation for comparison
## set.seed(120396)
## library(parallel)
## simres <- mclapply(X = seq(1, nrow(grid)), FUN = function(i) {
##     t1 <- rnorm(n = nsim, mean = grid$t1[i], sd = grid$se1[i])
##     t2 <- rnorm(n = nsim, mean = grid$t2[i], sd = grid$se2[i])
##     simdat <- do.call("rbind", lapply(X = seq_len(nsim), FUN = function(j) {
##         res <- twotrials(t1 = t1[j], t2 = t2[j], se1 = grid$se1[i],
##                          se2 = grid$se2[i])
##         data.frame(sim = j, res$summaries[,c("method", "est")])
##     }))
##     res <- data.frame(grid[i,], simdat)
##     return(res)
## }, mc.cores = pmax(detectCores() - 4, 1))
## save(simres, file = "simulation-results.RData")
## load("simulation-results.RData")
## ## simres |>
## ##     bind_rows() |>
## ##     group_by(method) |>
## ##     summarise(n = n(),
## ##               converged = mean(is.finite(est)))
## simsummaries <- simres |>
##     bind_rows() |>
##     group_by(method, se1, se2, t1, t2) |>
##     summarise(se = sd(est)) |>
##     mutate(type = "simulation")

## compute analytical SEs
grid2 <- expand.grid(se1 = se1, se2 = seq(min(se2), max(se2), length.out = 100),
                     t1 = t, t2 = t)
summaries <- do.call("rbind", lapply(X = seq(1, nrow(grid2)), FUN = function(i) {
    aSE <- sapply(X = list("Edgington" = seE, "Fisher" = seF,
                           "Meta-analysis" = seMA, "Pearson" = seP, "Tippett" = seT,
                           "Two-trials rule" = se2TR),
                  FUN = function(f) f(se1 = grid2$se1[i], se2 = grid2$se2[i],
                                      t1 = grid2$t1[i], t2 = grid2$t2[i]))
    res <- data.frame(method = names(aSE), grid2[i,], se = aSE, type = "analytical")
    return(res)
})) |>
    ## rbind(simsummaries) |> # uncomment if comparison with simulation SEs desired
    mutate(method = factor(method, levels = typelevels))

cols <- c("Trial 1" = "#CC79A7F2", "Trial 2" = "#888888F2",
          "Meta-analysis" = "#56B4E9F2", "Two-trials rule" = "#000000F2",
          "Tippett" = "#E69F00F2", "Edgington" = "#009E73F2",
          "Fisher" = "#F0E442F2", "Pearson" = "#0072B2F2")
ggplot(filter(summaries, type == "analytical",
              method != "Pearson", method != "Fisher"),
       ## filter(summaries, type == "analytical"),
       aes(x = se2, y = se, color = method)) +
    facet_grid(t2 ~ t1,
               labeller = label_bquote(theta[2] == .(t2), theta[1] == .(t1))) +
    geom_hline(yintercept = se1, alpha = 0.3) +
    geom_line(aes(linetype = method), alpha = 0.8, linewidth = 0.8) +
    ## geom_point(data = filter(summaries, type == "simulation"),
    ##            aes(shape = method), alpha = 0.9) +
    scale_color_manual(values = cols) +
    scale_linetype_manual(values = c(2, 1, 3, 4, 5, 6)) +
    labs(x = bquote(sigma[2]), y = "Standard error of median estimate",
         color = "", shape = "", linetype = "") +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          legend.position = "top", legend.key.width = unit(0.9,"cm"),
          strip.background = element_rect(fill = "#00000005"))
@
\caption{Comparison of median estimate standard errors across different
  scenarios of true trial effects $\theta_1$ and $\theta_2$ and trial standard
  error from the second trial $\sigma_2$. The standard error of the first trial
  is $\sigma_1 = \Sexpr{se1}$ across all scenarios. The standard errors from
  Fisher's and Pearson's methods are close to Tippett's method the two-trials
  rule, and not shown to make the plot easier to read.}
\label{fig:ses}
\end{figure}

We can see that the standard error from meta-analysis is always the lowest and
is always smaller than the minimum of the two standard errors
($\sigma_{\text{MA}} \leq \min\{\sigma_1, \sigma_2\}$). The standard error from
Edgington's method is equal (when $\sigma_1 = \sigma2$) to or larger than the
meta-analytic one, and can exceed the minimum standard error from the two trials
(e.g., for $\sigma_1 = 0.1$ and $\sigma_2 = 0.3$, it is $\sigma_{\text{E}} =
\Sexpr{round(seE(0.1, 0.3), 3)}$ ). The standard errors for both Edgington's
method and meta-analysis only depend on the trials' standard error, but not on
the true effects, so their standard errors are the same across all panels in
Figure~\ref{fig:ses}. This is not the case case for the two-trials rule and
Tippett's method, which show a more irregular behavior. When, the true trial
effects coincide ($\theta_1 = \theta_2$; panels on the diagonal), the combined
standard error decreases with decreasing standard error from the second trial
$\sigma_2$. However, when the true effect from the first trial is smaller than
the one from the second trial ($\theta_1 < \theta_2$; upper off-diagonal
panels), the combined standard error from Tippett's method remains constant
whereas the standard error from the two-trials rule changes drastically with
with changing $\sigma_2$. The opposite occurs when the effect from the first
trial is larger ($\theta_1 > \theta_2$; lower off-diagonal panels). This is
plausible, as these methods target the minimum (two-trials rule) or maximum
(Tippett) effect, meaning that the standard error of the trial with minimum or
maximum effect mainly drives the standard error of the combined estimate.

\bmsubsection{Limiting combined estimation functions}
\label{app:asymptotics}

Consider again the random variables $Y$ and $X$ as defined in
Appendix~\ref{app:expectation}. Their cumulative distribution functions can be
derived to be
\begin{align*}
  \Pr(Y \leq y)
  &= \Pr(\max\{\hat{\theta}_1 - \sigma_1 \, q, \hat{\theta}_2 - \sigma_2 \, q\} \leq y) \\
  &= \Pr(\hat{\theta}_1 - \sigma_1 \, q \leq y, \hat{\theta}_2 - \sigma_2 \, q \leq y) \\
  &= \Pr(\hat{\theta}_1 - \sigma_1 \, q \leq y) \times \Pr(\hat{\theta}_2 - \sigma_2 \, q \leq y) \\
  &= \Phi\left(\frac{y - \theta_1}{\sigma_1} + q\right) \times \Phi\left(\frac{y - \theta_2}{\sigma_2} + q\right)
\end{align*}
and
\begin{align*}
  \Pr(X \leq x)
  &= \Pr(\min\{\hat{\theta}_1 + \sigma_1 \, q, \hat{\theta}_2 + \sigma_2 \, q\} \leq x) \\
  &= 1 - \Pr(\hat{\theta}_1 + \sigma_1 \, q > x, \hat{\theta}_2 + \sigma_2 \, q > x) \\
  &= 1 - \{\Pr(\hat{\theta}_1 + \sigma_1 \, q > x) \times \Pr(\hat{\theta}_2 + \sigma_2 \, q > x)\} \\
  &= 1 - \left\{\Phi\left(\frac{\theta_1 - x}{\sigma_1} + q\right) \times \Phi\left(\frac{ \theta_2 - x}{\sigma_2} + q\right)\right\}.
\end{align*}
Letting the standard errors $\sigma_1$ and $\sigma_2$ got to zero, this leads to
\begin{align}
  \label{eq:limitcdfy}
  \lim_{\sigma_1, \sigma_2 \downarrow 0} \Pr(Y \leq y)
  &= 1_{[\theta_1, +\infty)}(y) \times 1_{[\theta_2, +\infty)}(y) \nonumber \\
  &= 1_{[\max\{\theta_1, \theta_2\}, +\infty)}(y)
\end{align}
and
\begin{align}
  \lim_{\sigma_1, \sigma_2 \downarrow 0} \Pr(X \leq x)
  &= 1 - \{1_{(-\infty, \theta_1]}(x) \times 1_{(-\infty, \theta_2]}(x)\} \nonumber \\
  %% = 1 - \{1_{(-\infty, \min\{\theta_1, \theta_2\}]}(x)\}
  &= 1_{[\min\{\theta_1, \theta_2\}, +\infty)}(x)
  \label{eq:limitcdfx}
\end{align}
where $1_A(x) = 1$ if $x \in A$ and 0 otherwise, and the constant $q$ vanishes.
Since~\eqref{eq:limitcdfy} and~\eqref{eq:limitcdfx} is the cumulative
distribution function of a degenerate random variable at $\max\{\theta_1,
\theta_2\}$ and $\min\{\theta_1, \theta_2\}$, respectively, this implies that
the combined estimation functions given by $X$ and $Y$ converge in probability
to $\max\{\theta_1, \theta_2\}$ and $\min\{\theta_1, \theta_2\}$, respectively,
for any constant $q$. Thus, all combined estimation functions from
Table~\ref{tab:constant} converge in probability to $\max\{\theta_1, \theta_2\}$
or $\min\{\theta_1, \theta_2\}$ as $\sigma_1$ and $\sigma_2$ decrease.

\bmsubsection{Approximate combined estimation functions}
\label{app:approxmu}
Suppose that the trials' individual \textit{p}-value functions
\begin{align*}
  &p_1(\mu) =
  \begin{cases}
    1 - \Phi\left(\frac{\hat{\theta}_1 - \mu}{\sigma_1}\right) & \text{for alternative = ``greater''} \\
     \Phi\left(\frac{\hat{\theta}_1 - \mu}{\sigma_1}\right) & \text{for alternative ``less''} \\
    \end{cases}&
  &~&
   &p_2(\mu) =
  \begin{cases}
    1 - \Phi\left(\frac{\hat{\theta}_2 - \mu}{\sigma_2}\right) & \text{for alternative = ``greater''} \\
     \Phi\left(\frac{\hat{\theta}_2 - \mu}{\sigma_2}\right) & \text{for alternative = ``less''} \\
    \end{cases}&
\end{align*}
are ``well-separated'' in the sense that in the region where $p_1(\mu)$ changes
from 0 to 1, $p_2(\mu)$ stays almost constant at 0 or 1, see the dotted lines in
Figure~\ref{fig:separated-pvals} for an example. This happens when either the
estimates $\hat{\theta}_1$ and $\hat{\theta}_2$ are far apart and/or the
standard errors $\sigma_1$ and $\sigma_2$ are small relative to the estimates
(provided the estimates are not equal). Note that asymptotically the individual
\textit{p}-value functions approach the step functions
\begin{align*}
  &\lim_{\sigma_1 \downarrow 0} p_1(\mu) =
  \begin{cases}
    1_{[\theta_1, +\infty)}(\mu) & \text{for alternative = ``greater''} \\
     1_{(-\infty, \theta_1]}(\mu) & \text{for alternative = ``less''} \\
    \end{cases}&
    &~&
  &\lim_{\sigma_2 \downarrow 0} p_2(\mu) =
    \begin{cases}
    1_{[\theta_2, +\infty)}(\mu) & \text{for alternative = ``greater''} \\
     1_{(-\infty, \theta_2]}(\mu) & \text{foralternative = ``less''} \\
    \end{cases}&
\end{align*}
Hence, with decreasing standard errors, the trials' \textit{p}-value functions
eventually become well-separated whenever the true effects $\theta_1$ and
$\theta_2$ are unequal.


\begin{figure}[!htb]
<< "fisher-pearson-edgington-approximation", fig.height = 3.5 >>=
## when trials have small standard error
museq <- seq(0.2, 0.8, 0.001)
t1 <- 0.3
t2 <- 0.6
se1 <- 0.05
se2 <- 0.07
z1 <- (t1 - museq)/se1
z2 <- (t2 - museq)/se2
p1 <- 1 - pnorm(z1)
p2 <- 1 - pnorm(z2)
pfis <- 1 - pchisq(q = -2*(log(p1) + log(p2)), df = 4)
ppear <- pchisq(q = -2*(log(1 - p1) + log(1 - p2)), df = 4)
e <- p1 + p2
pedg <- ifelse(e <= 1, e^2/2, 1 - (2 - e)^2/2)

a1 <- 0.025
a2 <- 0.975
estpear1 <- min(c(t1, t2) - c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = a1, df = 4))))
estfis1 <- max(c(t1, t2) + c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = 1 - a1, df = 4))))
estedg1 <- min(c(t1, t2) + c(se1, se2)*qnorm(p = sqrt(2*a1)))
estpear2 <- min(c(t1, t2) - c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = a2, df = 4))))
estfis2 <- max(c(t1, t2) + c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = 1 - a2, df = 4))))
estedg2 <- max(c(t1, t2) - c(se1, se2)*qnorm(p = sqrt(2*(1 - a2))))

par("mar" = c(4.1, 4.1, 1.5, 4.1), "oma" = c(0, 0, 0, 0))
cols <- c("Edgington" = "#009E73F2", "Fisher" = "#F0E442F2",
          "Pearson" = "#0072B2F2")
matplot(museq, cbind(p1, p2), lty = 3, col = c(1, 1), type = "l",
        xlab = bquote(mu), ylab = bquote(italic(p) * "-value"), las = 1,
        lwd = 1.5)
matlines(museq, cbind(pedg, pfis, ppear), lty = 1, col = cols, lwd = 1.5)
legend("right", legend = c("Trial 1", "Trial 2", "Edgington", "Fisher", "Pearson"),
       lty = c(3, 3, 1, 1, 1), col = c(1, 1, cols), lwd = c(1.5, 1.5, 1.5, 1.5, 1.5),
       cex = 0.8)
abline(h = c(a1, a2), lty = 1, col = adjustcolor(col = 1, alpha.f = 0.3))
axis(side = 4, at = c(a1, a2), las = 1)
segments(x0 = c(estedg1, estfis1, estpear1, estedg2, estfis2, estpear2),
         y0 = rep(0, 6), y1 = c(rep(a1, 3), rep(a2, 3)), col = rep(cols, 2),
         lty = 2)
points(x = c(estedg1, estfis1, estpear1, estedg2, estfis2, estpear2),
       y = c(rep(a1, 3), rep(a2, 3)), col = rep(cols, 2), pch = 20, cex = 0.7)

## ## for alternative "less"
## p1 <- pnorm((t1 - museq)/se1)
## p2 <- pnorm((t2 - museq)/se2)
## pfis <- 1 - pchisq(q = -2*(log(p1) + log(p2)), df = 4)
## ppear <- pchisq(q = -2*(log(1 - p1) + log(1 - p2)), df = 4)
## e <- p1 + p2
## pedg <- ifelse(e <= 1, e^2/2, 1 - (2 - e)^2/2)
## estpear1 <- max(c(t1, t2) + c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = a1, df = 4))))
## estfis1 <- min(c(t1, t2) - c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = 1 - a1, df = 4))))
## estedg1 <- max(c(t1, t2) - c(se1, se2)*qnorm(p = sqrt(2*a1)))
## estpear2 <- max(c(t1, t2) + c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = a2, df = 4))))
## estfis2 <- min(c(t1, t2) - c(se1, se2)*qnorm(p = exp(-0.5*qchisq(p = 1 - a2, df = 4))))
## estedg2 <- min(c(t1, t2) + c(se1, se2)*qnorm(p = sqrt(2*(1 - a2))))
## matplot(museq, cbind(p1, p2), lty = 3, col = c(1, 1), type = "l",
##         xlab = bquote(mu), ylab = bquote(italic(p) * "-value"), las = 1,
##         lwd = 1.5)
## matlines(museq, cbind(pedg, pfis, ppear), lty = 1, col = cols, lwd = 1.5)
## legend("right", legend = c("Trial 1", "Trial 2", "Edgington", "Fisher", "Pearson"),
##        lty = c(3, 3, 1, 1, 1), col = c(1, 1, cols), lwd = c(1.5, 1.5, 1.5, 1.5, 1.5),
##        cex = 0.8)
## abline(h = c(a1, a2), lty = 1, col = adjustcolor(col = 1, alpha.f = 0.3))
## axis(side = 4, at = c(a1, a2), las = 1)
## segments(x0 = c(estedg1, estfis1, estpear1, estedg2, estfis2, estpear2),
##          y0 = rep(0, 6), y1 = c(rep(a1, 3), rep(a2, 3)), col = rep(cols, 2),
##          lty = 2)
## points(x = c(estedg1, estfis1, estpear1, estedg2, estfis2, estpear2),
##        y = c(rep(a1, 3), rep(a2, 3)), col = rep(cols, 2), pch = 20, cex = 0.7)
@
\caption{Two well-separated \textit{p}-value functions (with alternative ``greater'')
  and the associated combined \textit{p}-value functions based on Fisher's, Pearson's,
  and Edgington's methods. The dashed vertical lines and points denote the 95\%
  CI limits computed with the approximate combined estimation
  functions~\eqref{eq:fisherest2}, \eqref{eq:pearsonest2},
  and~\eqref{eq:edgingtonprecise}. The effect estimates are $\hat{\theta}_1 =
  \Sexpr{t1}$ and $\hat{\theta}_2 = \Sexpr{t2}$ while the standard errors are
  $\sigma_1 = \Sexpr{se1}$ and $\sigma_2 = \Sexpr{se2}$.}
\label{fig:separated-pvals}
\end{figure}

In case of well-separated \textit{p}-value functions, we can approximate the combined
\textit{p}-value function from Fisher's, Pearson's, and Edgington's method by setting
one of the \textit{p}-values to 0 or 1, depending on alternative and combination
method, and derive an approximate but closed-form combined estimation function.
For example, in Figure~\ref{fig:separated-pvals} the combined \textit{p}-value from
Fisher's method~\eqref{eq:fisher} remains virtually constant for increasing
$\mu$ when the first individual \textit{p}-function increases and only starts to
increase as the second \textit{p}-value function increases.

We may hence approximate Fisher's combined \textit{p}-value by
\begin{align}
  p_{\text{F}}(\mu) =
  \begin{cases}
    1 - \Pr\left[\chi^{2}_{4} \leq -2 %\left[\underbrace{\log (1)}_{=0} +
    \log\left\{1 - \Phi\left(\max\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\} %\right]
    \right] &  \text{for alternative = "greater"} \\
  1 - \Pr\left[\chi^{2}_{4} \leq -2 %\left[\underbrace{\log (1)}_{=0} +
    \log\left\{\Phi\left(\min\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\} %\right]
    \right] &  \text{for alternative = "less".} \\
  \end{cases}
  \label{eq:fisherapprox}
\end{align}
%% Similarly, the combined \textit{p}-value function for the alternative ``less'' may be
%% approximated by
%% \begin{align}
%%   p_{\text{F}}(\mu) =
%%   1 - \Pr\left[\chi^{2}_{4} \leq -2 %\left[\underbrace{\log (1)}_{=0} +
%%     \log\left\{1 - \Phi\left(\min\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\} %\right]
%%     \right].
%%   \label{eq:fisherapprox2}
%% \end{align}
The corresponding combined estimation function can then be obtained by
equating~\eqref{eq:fisherapprox} to $a$ and solving for $\mu$, which leads to
\begin{equation}
  \label{eq:fisherest2}
  \hat{\mu}_{\text{F}}(a) =
  \begin{cases}
    \max\{\hat{\theta}_{1} + \sigma_{1} \, z_{\exp\{-\chi^{2}_{4}(1 - a)/2\}},
    \hat{\theta}_{2} + \sigma_{2} \, z_{\exp\{-\chi^{2}_{4}(1 - a)/2\}}\} &  \text{for alternative = "greater"} \\
    \min\{\hat{\theta}_{1} - \sigma_{1} \, z_{\exp\{-\chi^{2}_{4}(1 - a)/2\}},
    \hat{\theta}_{2} - \sigma_{2} \, z_{\exp\{-\chi^{2}_{4}(1 - a)/2\}}\} &  \text{for alternative = "less".} \\
  \end{cases}
\end{equation}
The dashed yellow vertical lines in Figure~\ref{fig:separated-pvals} show the
limits of a 95\% CI computed via~\eqref{eq:fisherest2}, demonstrating that the
approximation is accurate in this case, despite the finite standard errors.


In an analogous fashion, the combined \textit{p}-value function based on Pearson's
method can be approximated by
\begin{align*}
  p_{\text{P}}(\mu) =
  \begin{cases}
    \Pr\left[\chi^{2}_{4} \leq -2 %\left[\underbrace{\log (1 - 0)}_{=0} +
      \log\left\{\Phi\left(\min\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\} %\right]
    \right] &  \text{for alternative = "greater"} \\
      \Pr\left[\chi^{2}_{4} \leq -2 %\left[\underbrace{\log (1 - 0)}_{=0} +
      \log\left\{1 - \Phi\left(\max\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\} %\right]
    \right] &  \text{for alternative = "less"}
  \end{cases}
\end{align*}
leading to the approximate combined estimation function
\begin{equation}
  \label{eq:pearsonest2}
  \hat{\mu}_{\text{P}}(a) =
  \begin{cases}
    \min\{\hat{\theta}_{1} - \sigma_{1} \, z_{\exp\{-\chi^{2}_{4}(a)/2\}},
    \hat{\theta}_{2} - \sigma_{2} \, z_{\exp\{-\chi^{2}_{4}(a)/2\}}\} &  \text{for alternative = "greater"} \\
    \max\{\hat{\theta}_{1} + \sigma_{1} \, z_{\exp\{-\chi^{2}_{4}(a)/2\}},
    \hat{\theta}_{2} + \sigma_{2} \, z_{\exp\{-\chi^{2}_{4}(a)/2\}}\} &  \text{for alternative = "less"}. \\
  \end{cases}
\end{equation}
The functions~\eqref{eq:fisherest2} and~\eqref{eq:pearsonest2} based on Fisher's
and Pearson's methods have a striking similarity to the combined estimation
functions based on Tippett's method~\eqref{eq:tippest} and the two-trials
rule~\eqref{eq:2trialsest}, respectively, as they again involve shifted
maxima/minima of the trial estimates.


In a similar way, Edgington's combined \textit{p}-value function can be approximated by
\begin{align*}
  p_{\text{E}}(\mu) =
  \begin{cases}
    \left\{1 - \Phi\left(\min\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\}^{2} \big/ \,2
    & \text{if} ~ \mu < \dfrac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2} \\
    \dfrac{1}{2} & \text{if} ~  \mu = \dfrac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2} \\
    1 - \left\{\Phi\left(\max\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\}^{2} \big/ \,2 & \text{else}
  \end{cases}
\end{align*}
for the alternative ``greater'' and with
\begin{align*}
  p_{\text{E}}(\mu) =
  \begin{cases}
    \left\{ \Phi\left(\max\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\}^{2} \big/ \,2
    & \text{if} ~  \mu > \dfrac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2}  \\
    \dfrac{1}{2} & \text{if} ~  \mu = \dfrac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2} \\
    1- \left\{1 - \Phi\left(\min\left\{\frac{\hat{\theta}_1 - \mu}{\sigma_1}, \frac{\hat{\theta}_2 - \mu}{\sigma_2}\right\}\right)\right\}^{2} \big/ \,2 & \text{else}
  \end{cases}
\end{align*}
for the alternative ``less''. Consequently, the approximate combined estimation
function is
\begin{equation}
  \label{eq:edgingtonprecise}
  \hat{\mu}_{\text{E}}(a) =
  \begin{cases}
    \min\{\hat{\theta}_{1} + \sigma_{1} \, z_{\sqrt{2a}}, \hat{\theta}_{2} + \sigma_{2} \, z_{\sqrt{2a}}\} & \text{for} ~ a < 1/2 \\
    \dfrac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2} & \text{for} ~ a = 1/2 \\
    \max\{\hat{\theta}_{1} - \sigma_{1} \, z_{\sqrt{2(1 - a)}}, \hat{\theta}_{2} - \sigma_{2} \, z_{\sqrt{2(1 - a)}}\} & \text{for} ~ a > 1/2 \\
  \end{cases}
\end{equation}
for the alternative ``greater'' and
\begin{equation}
  \label{eq:edgingtonprecise2}
  \hat{\mu}_{\text{E}}(a) =
  \begin{cases}
    \max\{\hat{\theta}_{1} - \sigma_{1} \, z_{\sqrt{2a}}, \hat{\theta}_{2} - \sigma_{2} \, z_{\sqrt{2a}}\} & \text{for} ~ a < 1/2 \\
    \dfrac{\hat{\theta}_1/\sigma_1 + \hat{\theta}_2/\sigma_2}{1/\sigma_1 + 1/\sigma_2} & \text{for} ~ a = 1/2 \\
    \min\{\hat{\theta}_{1} + \sigma_{1} \, z_{\sqrt{2(1 - a)}}, \hat{\theta}_{2} + \sigma_{2} \, z_{\sqrt{2(1 - a)}}\} & \text{for} ~ a > 1/2 \\
  \end{cases}
\end{equation}
for the alternative ``less''. The combined estimation
functions~\eqref{eq:edgingtonprecise} and~\eqref{eq:edgingtonprecise2} also
include the closed-form solution for the median estimate ($a = 1/2$)
from~\eqref{eq:edgingtonpointest} as this value does not require any
approximation. Surprisingly, a $(1 - \alpha) \times 100\%$ CI constructed
from~\eqref{eq:edgingtonprecise} or~\eqref{eq:edgingtonprecise2} always includes
the individual estimates $\hat{\theta}_1$ and $\hat{\theta}_2$ since the lower
limit ($a = \alpha/2$) is always smaller than the minimum of the two effect
estimates, and the upper limit ($a = 1 - \alpha/2$) is always larger than the
maximum of the two. This demonstrates that Edgington's method reacts to
heterogeneity by widening its CI to include both trial effect estimates.


All of these approximations become more accurate with decreasing standard errors
as the individual \textit{p}-value functions become more separated. Since all
approximate combined estimation
functions~\eqref{eq:fisherest2}--\eqref{eq:edgingtonprecise2} are essentially
shifted minima and maxima (apart from the median estimate of Edgington's
method), the results from Appendix~\ref{app:asymptotics} apply. That is, as the
standard errors $\sigma_1$ and $\sigma_2$ decrease toward zero, all minima
converge in probability to $\min\{\theta_1,\theta_2\}$ while all maxima converge
to $\max\{\theta_1,\theta_2\}$.


<< "sessionInfo1", eval = Reproducibility, results = "asis" >>=
## print R sessionInfo to see system information and package versions
## used to compile the manuscript (set Reproducibility = FALSE, to not do that)
cat("\\newpage \\section*{Computational details}")
@
<< "sessionInfo2", echo = Reproducibility, results = Reproducibility, size = "scriptsize" >>=
cat(paste(Sys.time(), Sys.timezone(), "\n"))
sessionInfo()
@

\end{document}
